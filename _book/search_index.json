[
["introduction-to-r.html", "Statistical computing with R Chapter 1 Introduction to R 1.1 What do you need to download? 1.2 Creating variables 1.3 Vectors 1.4 Matrices 1.5 Installing libraries 1.6 Introduction to data.frames 1.7 Factors 1.8 Lists 1.9 Basic data summaries with R References", " Statistical computing with R Víctor Peña 2019-08-28 Chapter 1 Introduction to R 1.1 What do you need to download? You’ll need: R, which you can download here. RStudio, which you can download here. This Rstudio cheat sheet might be useful, especially if you want to learn some shortcuts that will help you write code faster. 1.2 Creating variables We can create variables by assigning them values: firstvariable = 0 secondvariable = 10 thirdvariable = TRUE fourthvariable = &quot;hello&quot; If we want to print a variable, we can type its name. For example: fourthvariable ## [1] &quot;hello&quot; The names of the variables are case sensitive. For example, if we try to print Fourthvariable, we’ll get an error because R doesn’t recognize it (try it yourself). With R, we can also assign values with &lt;- instead of =. For example, the following code is equivalent to the first chunk of code: firstvariable &lt;- 0 secondvariable &lt;- 10 thirdvariable &lt;- TRUE fourthvariable &lt;- &quot;hello&quot; There isn’t any practical difference between using one or the other. I tend to use = because it’s less work. We can comment code writing # followed by some text. For example, # The code below creates a variable named greetings greetings = &quot;hello&quot; As we learn more R, we’ll write somewhat complicated code. It’s good practice to add comments before steps that aren’t obvious (so that you don’t forget what the code does next time you look at it). We can rewrite variables. For example, if we type firstvariable = 3 the previous value of firstvariable has been overwritten. Now it’s equal to 3: firstvariable ## [1] 3 We can see the “type” of the variables using the function class: class(firstvariable) ## [1] &quot;numeric&quot; class(thirdvariable) ## [1] &quot;logical&quot; class(fourthvariable) ## [1] &quot;character&quot; The names of the types of these variables are intuitive, but here’s an explanation: numeric variables can take on numerical values. logical variables can take on the values TRUE and FALSE. The values TRUE and FALSE can be abbreviated to T and F. character variables are characters. The characters can be numbers. The values of variables of type character are written between quotation marks. For example var = &quot;3&quot; creates a variable called var whose class is character. An equivalent alternative is using single quotes. For example, we could also equivalently write var = '3'. There is no difference. I tend to use double quotes, but sometimes I might use single quotes instead. There are other types of variables and we’ll see them as we learn more R. Exercise What are the types of the following variables? var1 = 1000 var2 = 1e3 var3 = &quot;1000&quot; var4 = &quot;1e3&quot; var5 = &quot;T&quot; var6 = FALSE 1.2.1 Operations with variables We can add, subtract, multiply, divide, and exponentiate numeric variables: firstvariable+secondvariable ## [1] 13 firstvariable-secondvariable ## [1] -7 firstvariable*secondvariable ## [1] 30 firstvariable^secondvariable # exponentiation ## [1] 59049 We can combine operations. For example, we can compute the average of firstvariable and secondvariable as (firstvariable+secondvariable)/2 ## [1] 6.5 R has a built-in mean function, which we’ll see later. We can’t add, subtract, multiply, divide or exponentiate character variables (try it out: it’ll give you an error), but we can add, subtract, multiply, divide or exponentiate logical variables. If the variable is TRUE it’ll be treated as a 1; if it’s FALSE, it’ll be treated as a 0: logi1 = T logi2 = F logi1+logi2 ## [1] 1 logi1*logi2 ## [1] 0 logi1/logi2 ## [1] Inf logi1^logi2 ## [1] 1 We can combine logical and numeric variables in operations. Again, TRUE will be treated as a 1, and FALSE will be treated as a 0. Exercise Let var1 = 3, var2 = -3, var3 = 2, var4 = TRUE, and var5 = &quot;0&quot;. Find the values of the following operations. Try to guess what the values will be before trying in R, just to make sure you understand the process. (var1 + var3*var4)/4 var3^var1+var5^2 var1^0+var2^0 We can also do operations without using any variables at all. For example, 6/2*(2+1) ## [1] 9 Exercise Find the value of the following expressions: \\(10^3-3 \\cdot 4\\) \\(\\frac{(6+4)\\cdot 3}{2}\\) \\(\\frac{3-4}{2+3}\\) Think about what 6/2*(2+1+TRUE) should be without using R. Then, try what R gives you and compare. 1.2.2 Arithmetic functions R has built-in functions such as sqrt, exp, log, etc. sqrt(4) ## [1] 2 exp(firstvariable) ## [1] 20.08554 log(10, base=2) ## [1] 3.321928 If you’re not sure how a function works, you can ask for help by writing ? before the name of the function. The number \\(\\pi\\) is “pre-defined” as a variable. That is, pi ## [1] 3.141593 Note that we never defined a variable called pi, but the code above still worked. Exercise Let var1 = TRUE, var2 = 1e3, var3 = pi, var4 = -3. Find the values of the operations below. \\(\\frac{(\\exp(\\mathrm{var1}) + \\sqrt{\\mathrm{var3}})^2}{\\mathrm{var4}+\\mathrm{var3}}\\) \\(3 -\\frac{\\mathrm{var2}-\\mathrm{var4}}{3+\\mathrm{TRUE}}\\) \\(\\frac{\\log_{10}(\\mathrm{var2})}{\\mathrm{var1}}\\) \\(\\exp(\\sqrt{-1} \\pi) + 1\\) 1.3 Vectors We can define vectors as follows: x1 = c(1, 2, 3, 4, 5, 6) y1 = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;efg&quot;) z1 = c(&quot;a&quot;, 2, 3, &quot;e&quot;) We can print them by writing their name. For example, z1 ## [1] &quot;a&quot; &quot;2&quot; &quot;3&quot; &quot;e&quot; We can find the types of their entries with class, just as we did with variables that only had one entry: class(x1) ## [1] &quot;numeric&quot; class(y1) ## [1] &quot;character&quot; class(z1) ## [1] &quot;character&quot; Note that if a vector has mixed numeric and character entries, it gets saved as character (see z1). We can create ranges of values with : 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 10:6 ## [1] 10 9 8 7 6 You can also find the length of a vector: length(z1) ## [1] 4 1.3.1 Operations with numeric vectors We can add, multiply, divide, etc. all the components of a numeric vector by the same number: x1+5 ## [1] 6 7 8 9 10 11 x1*5 ## [1] 5 10 15 20 25 30 x1/5 ## [1] 0.2 0.4 0.6 0.8 1.0 1.2 We can add and subtract vectors of the same length: x2 = c(7, 8, 9, 10, 11, 12) x1+x2 ## [1] 8 10 12 14 16 18 x1-x2 ## [1] -6 -6 -6 -6 -6 -6 Similarly, we can do componentwise multiplication and division: x1*x2 ## [1] 7 16 27 40 55 72 x1/x2 ## [1] 0.1428571 0.2500000 0.3333333 0.4000000 0.4545455 0.5000000 If two vectors are of different lengths, we have to be careful! R won’t give us a warning message: x1 ## [1] 1 2 3 4 5 6 x3 = c(2,3) x1+x3 ## [1] 3 5 5 7 7 9 x1*x3 ## [1] 2 6 6 12 10 18 We can compute means, standard deviations, variances, etc: mean(x1) ## [1] 3.5 sd(x1) ## [1] 1.870829 var(x1) ## [1] 3.5 We can also take the sum or the product of the elements of a numeric vector: sum(x1) ## [1] 21 prod(x1) ## [1] 720 Exercise What is the value of the sum \\(1 + 2 + 3 + \\, \\cdots \\, + 2019\\)? What about the product \\(1 \\cdot 2 \\cdot 3 \\cdot \\, \\cdots \\, \\cdot 10\\)? [It’s not part of the (graded) question, but try computing \\(1 \\cdot 2 \\cdot 3 \\cdot \\, \\cdots \\, \\cdot 2019\\). What do you get?] The final grade of a course is equal to the average of 3 assignments. A student got a 100% in 2 of the tests and didn’t show up for the last one. What is her final grade? (in grade %). Consider the same setup that we had in the previous question, but now assume that the instructor computes the final grade using the geometric mean instead. What is her final grade? Find the usual (arithmetic) average, the geometric average, and the standard deviation of the grades of the following 3 students in the class. Alice got a 75 in the first, second, and third exam. Bob got a 100 in the first one, another perfect 100 in the second exam, but he tanked the third and got only a 25. Finally, Carol started strong with a 93, but then lost steam. In the second exam, she got a 70, and in the last exam, she got a 63. Comment on the results. [To be discussed in class.] Let x = 1:10 and y = 11:20. What is the value that you get after applying the R equivalent of the function SUMPRODUCT in Excel? 1.3.2 Concatenating We can add new entries in an existing vector as follows: x1 ## [1] 1 2 3 4 5 6 c(x1,10) # add at the end ## [1] 1 2 3 4 5 6 10 c(10, x1) # add at the beginning ## [1] 10 1 2 3 4 5 6 We can concatenate vectors, too: c(x1, x2) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 1.3.3 Indexing We can look at particular entries of a vector using brackets. x1 ## [1] 1 2 3 4 5 6 x1[1] # first entry ## [1] 1 x1[4] # 4th entry ## [1] 4 x1[length(x1)] # last entry ## [1] 6 In R, indices start at 1 (in some other programming languages, indices start at 0). We can access subsets of vectors using vectors. For example, if we want to print the third and fifth entries of x1: x1[c(3,5)] ## [1] 3 5 We can subset using ranges of values with :. For instance, if we want to select the second, third, fourth, and fifth entries of x1: x1[2:5] ## [1] 2 3 4 5 We can also index by excluding certain observations. For example, if we want a vector that contains all the components in x1 except the first one, we can write x1[-1] ## [1] 2 3 4 5 6 This trick can also be used with vectors and ranges: x1[-c(3,5)] ## [1] 1 2 4 6 x1[-(2:5)] ## [1] 1 6 Exercise This exercise is not on TopHat, but please do it. Otherwise, you might get stuck further on. Create a vector that contains the second, fourth, and sixth entries of x1 = c(1,2,3,1,2,5,2,2,2). Create a vector that contains all but the second, fourth, and sixth entries of x1 = c(1,2,3,1,2,5,2,2,2). Let x = 1:50 and y = 51:100. Create a new vector z that concatenates the entries of x and y. Then, create a vector that contains the even entries of z and another one that contains the odd entries of z. 1.4 Matrices Matrices are “boxes” that can contain numeric, logical, or character entries. We can create matrices as follows: A1 = matrix(c(1,2,3,4), nrow=2, ncol=2, byrow=TRUE) # read by row A2 = matrix(c(1,3,2,4), nrow=2, ncol=2, byrow=FALSE) # read by column And we can print them as usual: A1 ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 A2 ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 If byrow isn’t specified, the default is byrow = FALSE: A3 = matrix(c(TRUE, FALSE, TRUE, FALSE), nrow = 2, ncol = 2) A3 ## [,1] [,2] ## [1,] TRUE TRUE ## [2,] FALSE FALSE Doing operations with matrices is straightforward: A1*A2 # componentwise product ## [,1] [,2] ## [1,] 1 4 ## [2,] 9 16 A1+A2 # componentwise addition ## [,1] [,2] ## [1,] 2 4 ## [2,] 6 8 log(A1) # taking the log of the components ## [,1] [,2] ## [1,] 0.000000 0.6931472 ## [2,] 1.098612 1.3862944 A1[1,] # multiply all of A1 by 7 ## [1] 1 2 7*A1[1,] # multiply the first row of A1 by 7 ## [1] 7 14 Indexing matrices is similar to indexing vectors. For example, if we want to access the element in the first row and second column of A1: A1[1,2] # accessing entries: rows first, then columns ## [1] 2 You can also get out full rows and columns of a matrix. For example, if you want to select the first row of A1: A1[1,] ## [1] 1 2 If you want to access the second column: A1[,2] ## [1] 2 4 You can also access subsets of matrices. For example, let B = matrix(c(1:9), nrow = 3, ncol=3) You can access the first two rows and columns as follows B[1:2,1:2] ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 You can name the rows and columns of matrices. For example if we want the rows of B to be called R1, R2, and R3 and the columns of B to be named C1, C2, C3, we can type rownames(B) = c(&quot;R1&quot;, &quot;R2&quot;, &quot;R3&quot;) colnames(B) = c(&quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;) And then print B ## C1 C2 C3 ## R1 1 4 7 ## R2 2 5 8 ## R3 3 6 9 The functions colSums and rowSums give us column sums and row sums of matrices, which is often useful. For example: rowSums(B) ## R1 R2 R3 ## 12 15 18 colSums(B) ## C1 C2 C3 ## 6 15 24 You can also apply the function sum to the matrix to add up all the numbers in the matrix: sum(B) ## [1] 45 Exercise Bob is on a health kick and is keeping track of the macronutrients and calories in what he eats. Yesterday, he ate Breakfast: 50g of carbs, 8g of fat, and 20g of protein Lunch: 60g of carbs, 30g of fat, and 40g of protein Dinner: 40g of carbs, 30g of fat, 40g of protein Create a matrix that combines the information above. Each meal should be in a different row and the columns should contain the grams of carbs, fat, and protein in the meals. The rownames of the matrix should be breakfast, lunch, and dinner. The colnames should be carbs, fat, and protein. Once you’ve done that, use R to answer the following questions: How many grams of carbs, fat, and protein did Bob eat yesterday? (give them separately; your answer should look something like 50g of carbs, 30g of fat, 20g of protein, but with different numbers) Assume that each gram of carbs yields 4 calories, each gram of protein yields 4 calories, and each gram of fat yields 9 calories. How many calories did Bob eat for breakfast, lunch, and dinner yesterday? (give them separately; your answer should look something like 200 calories for breakfast, 500 calories for lunch, and 300 for dinner, but with different numbers) yesterday? How many calories did he eat in total? Did he stay under his goal of 1800 calories per day? What percentage of the calories he ate yesterday come from carbs, protein, and fat, respectively? (give them separately; your answer should look something like 100 cal from carbs, 300 cal from fat, 300 cal from protein, but potentially with different numbers). He is trying to follow the so-called 40/30/30 diet, where 40 percent of the calories eaten should come from carbs, 30 percent from protein, and 30 percent from fat. Is he close to his goal? If not, suggest how he could get closer You can add rows and columns to a matrix using rbind and cbind, respectively. Let’s define 2 matrices A and B: A = matrix(c(1,2,3,4), nrow=2, ncol=2) B = matrix(c(5,6,7,8), nrow=2, ncol=2) Let’s use rbind: rbind(A,B) ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 ## [3,] 5 7 ## [4,] 6 8 And cbind: cbind(A,B) ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 As you can imagine, the order matters. Try out rbind(B,A) and check that you get the output that you’d expect. ** Create exercise where they have to combine matrices and compute some stuff ** 1.5 Installing libraries Statisticians use R because there are many libraries that contain useful functions. We can install libraries with install.packages. For example, if we want to install ggplot2, which is a useful library for plotting: install.packages(&#39;ggplot2&#39;) Once the library is installed, we can load it using library(). If we want to load ggplot2, we need to type: library(ggplot2) 1.6 Introduction to data.frames We’ll use the dataset iris, which is in the built-in library datasets. First, we load it: data(iris) You can get information about the dataset by typing ?iris. The class of the dataset is data.frame (and others), which are matrices that have columns that can have different types. The function str gives us some information about the variables in the dataset: str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... We have 150 observtions and 5 variables. The first 4 variables are numerical and Species is a factor. We’ll cover factors in the next section. You can get a quick summary of the data with summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## We’ll come back to this later. We can print the first and last 5 observations in the dataset using head and tail: head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa tail(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica We can index the rows and columns of mpg using the same syntax we used for indexing matrices: iris[3:7,c(1,4:5)] ## Sepal.Length Petal.Width Species ## 3 4.7 0.2 setosa ## 4 4.6 0.2 setosa ## 5 5.0 0.2 setosa ## 6 5.4 0.4 setosa ## 7 4.6 0.3 setosa With data.frames, we can extract variables using $ followed by their name. For example, if we want to create a variable named spec that contains the column of iris which has named Species: spec = iris$Species We can also index by logical conditions. For instance, if we want to work with the subset of the data where Species is equal to setosa iris[iris$Species == &quot;setosa&quot;,] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 17 5.4 3.9 1.3 0.4 setosa ## 18 5.1 3.5 1.4 0.3 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 20 5.1 3.8 1.5 0.3 setosa ## 21 5.4 3.4 1.7 0.2 setosa ## 22 5.1 3.7 1.5 0.4 setosa ## 23 4.6 3.6 1.0 0.2 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 25 4.8 3.4 1.9 0.2 setosa ## 26 5.0 3.0 1.6 0.2 setosa ## 27 5.0 3.4 1.6 0.4 setosa ## 28 5.2 3.5 1.5 0.2 setosa ## 29 5.2 3.4 1.4 0.2 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 31 4.8 3.1 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 33 5.2 4.1 1.5 0.1 setosa ## 34 5.5 4.2 1.4 0.2 setosa ## 35 4.9 3.1 1.5 0.2 setosa ## 36 5.0 3.2 1.2 0.2 setosa ## 37 5.5 3.5 1.3 0.2 setosa ## 38 4.9 3.6 1.4 0.1 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 40 5.1 3.4 1.5 0.2 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 43 4.4 3.2 1.3 0.2 setosa ## 44 5.0 3.5 1.6 0.6 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 47 5.1 3.8 1.6 0.2 setosa ## 48 4.6 3.2 1.4 0.2 setosa ## 49 5.3 3.7 1.5 0.2 setosa ## 50 5.0 3.3 1.4 0.2 setosa Notice that we used == instead of a single =. We’ll learn more about data-subsetting in the next chapter. Exercise Not on Top Hat, but I strongly recommend doing it. Create a new data.frame named color that contains all the rows in iris so that Species is equal to versicolor. Create a new data.frame named first100 that contains the first 100 rows of iris. Create a new data.frame named Petal that only contains the variables Petal.Length and Petal.Width. Creating data.frames from scratch is straightforward. For example, df = data.frame(var1 = c(1, 2, 3), var2 = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)) creates a data.frame with two columns named var1 and var2 which contain the vectors c(1,2,3) and c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;). You can create a data.frame from existing vectors as well. For example, the following chunk of code is equivalent to the previous one var1 = c(1, 2, 3) var2 = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) df = data.frame(var1, var2) The rows and columns of data.frames can be named using rownames and colnames (just as we did with matrix-type variables). We can easily add new variables to an existing data.frame. For example, we can add var3 = c(&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;) By writing df$var3 = var3 We could’ve also skipped a step and written df$var3 = c(&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;) Another alternative is using cbind, which we saw when we were working with matrices. The function rbind works with data.frames as well. 1.7 Factors factor is a variable type in R useful for encoding categorical variables. In the iris dataset, species is a factor. Variables of type character and factor are (conceptually similar) but they have different properties. When we work with data.frames, we’ll work with factors. When we work with matrices, we’ll work with character-type variables. This can be a bit of a headache because, sometimes, we want to convert matrix objects to data.frames. We’ll see some of that later in the semester. Defining a factor from scratch is easy: fac1 = factor(c(&quot;dog&quot;,&quot;cat&quot;,&quot;cat&quot;,&quot;dog&quot;)) We can use summary to create a quick table: summary(fac1) ## cat dog ## 2 2 The default ordering of the categories in a factor is alphabetical, which isn’t always the best or most intutive. We can see the different categories (in R lingo, levels) of a factor and its ordering using levels: levels(fac1) ## [1] &quot;cat&quot; &quot;dog&quot; Exercise In the iris dataset, how many species of type setosa are there? Let’s use a dataset named hsb2 to illustrate this point. hsb2 = read.csv(&quot;http://vicpena.github.io/sta9750/spring19/hsb2.csv&quot;) The dataset contains a variable called ses, which is socioeconomic status of the student. It can take on the values low, middle, and high. Unfortunately, the default ordering of the factor is alphabetical, that is: levels(hsb2$ses) ## [1] &quot;high&quot; &quot;low&quot; &quot;middle&quot; The problem with this ordering is that if we create tables, plots, etc. R will use this ordering, which is counterintuitive. For instance, if we create a 2 x 2 table of ses and race, we get table(hsb2$ses, hsb2$race) ## ## african american asian hispanic white ## high 3 3 4 48 ## low 11 3 9 24 ## middle 6 5 11 73 This is not great. How can we reorder the levels of a factor? The answer is hsb2$ses = factor(hsb2$ses, levels = c(&quot;low&quot;, &quot;middle&quot;, &quot;high&quot;)) The code above rewrites the ses variable in hsb2 to an ordered factor whose levels are low, middle, and high (in that order). Here’s the code to verify that ses is now ordered: levels(hsb2$ses) ## [1] &quot;low&quot; &quot;middle&quot; &quot;high&quot; table(hsb2$ses, hsb2$race) ## ## african american asian hispanic white ## low 11 3 9 24 ## middle 6 5 11 73 ## high 3 3 4 48 Exercise Not on TopHat. Create a factor which takes on the values bad, good, mediocre. Reorder it so that the levels are sorted as bad, mediocre, good. 1.8 Lists We won’t say much about lists, but they’re useful if we want to keep objects of different types in a single place. For example, suppose that we have a vector and a matrix: v = 1:6 m = matrix(c(1,0,0,1),byrow=T,nrow=2) Then, the following code creates a list whose entries are the vector v and the matrix m: l = list(v,m) We can access, say, the second element of the list with l[[2]] ## [,1] [,2] ## [1,] 1 0 ## [2,] 0 1 And we can do things such as l[[2]][2,1] ## [1] 0 l[[1]][4] ## [1] 4 We can add a new element to the list indexing by a new element v2 = 3:4 l[[3]] = v2 We probably won’t see lists again in the course, but it’s good to know that they exist. 1.9 Basic data summaries with R In this section, we’ll use the mpg dataset in library(ggplot2). library(ggplot2) data(mpg) We can get quick summaries of numeric variables with summary. summary(mpg) ## manufacturer model displ year ## Length:234 Length:234 Min. :1.600 Min. :1999 ## Class :character Class :character 1st Qu.:2.400 1st Qu.:1999 ## Mode :character Mode :character Median :3.300 Median :2004 ## Mean :3.472 Mean :2004 ## 3rd Qu.:4.600 3rd Qu.:2008 ## Max. :7.000 Max. :2008 ## cyl trans drv cty ## Min. :4.000 Length:234 Length:234 Min. : 9.00 ## 1st Qu.:4.000 Class :character Class :character 1st Qu.:14.00 ## Median :6.000 Mode :character Mode :character Median :17.00 ## Mean :5.889 Mean :16.86 ## 3rd Qu.:8.000 3rd Qu.:19.00 ## Max. :8.000 Max. :35.00 ## hwy fl class ## Min. :12.00 Length:234 Length:234 ## 1st Qu.:18.00 Class :character Class :character ## Median :24.00 Mode :character Mode :character ## Mean :23.44 ## 3rd Qu.:27.00 ## Max. :44.00 We can create one-way and two-way tables with table table(mpg$manufacturer) ## ## audi chevrolet dodge ford honda hyundai ## 18 19 37 25 9 14 ## jeep land rover lincoln mercury nissan pontiac ## 8 4 3 4 13 5 ## subaru toyota volkswagen ## 14 34 27 table(mpg$manufacturer,mpg$year) ## ## 1999 2008 ## audi 9 9 ## chevrolet 7 12 ## dodge 16 21 ## ford 15 10 ## honda 5 4 ## hyundai 6 8 ## jeep 2 6 ## land rover 2 2 ## lincoln 2 1 ## mercury 2 2 ## nissan 6 7 ## pontiac 3 2 ## subaru 6 8 ## toyota 20 14 ## volkswagen 16 11 table(mpg$year) ## ## 1999 2008 ## 117 117 We can also find proportion tables with prop.table. If we want to use prop.table, we have to save a table object first, and then call prop.table. For example: manutable = table(mpg$manufacturer) prop.table(manutable) ## ## audi chevrolet dodge ford honda hyundai ## 0.07692308 0.08119658 0.15811966 0.10683761 0.03846154 0.05982906 ## jeep land rover lincoln mercury nissan pontiac ## 0.03418803 0.01709402 0.01282051 0.01709402 0.05555556 0.02136752 ## subaru toyota volkswagen ## 0.05982906 0.14529915 0.11538462 We can create two-way proportion tables using the same idea. For instance, manuyear = table(mpg$manufacturer, mpg$year) prop.table(manuyear) ## ## 1999 2008 ## audi 0.038461538 0.038461538 ## chevrolet 0.029914530 0.051282051 ## dodge 0.068376068 0.089743590 ## ford 0.064102564 0.042735043 ## honda 0.021367521 0.017094017 ## hyundai 0.025641026 0.034188034 ## jeep 0.008547009 0.025641026 ## land rover 0.008547009 0.008547009 ## lincoln 0.008547009 0.004273504 ## mercury 0.008547009 0.008547009 ## nissan 0.025641026 0.029914530 ## pontiac 0.012820513 0.008547009 ## subaru 0.025641026 0.034188034 ## toyota 0.085470085 0.059829060 ## volkswagen 0.068376068 0.047008547 The table above is a total proportions table (that is, if we add up all the numbers in the table, we get 1). If we want row proportions, prop.table(manuyear, 1) ## ## 1999 2008 ## audi 0.5000000 0.5000000 ## chevrolet 0.3684211 0.6315789 ## dodge 0.4324324 0.5675676 ## ford 0.6000000 0.4000000 ## honda 0.5555556 0.4444444 ## hyundai 0.4285714 0.5714286 ## jeep 0.2500000 0.7500000 ## land rover 0.5000000 0.5000000 ## lincoln 0.6666667 0.3333333 ## mercury 0.5000000 0.5000000 ## nissan 0.4615385 0.5384615 ## pontiac 0.6000000 0.4000000 ## subaru 0.4285714 0.5714286 ## toyota 0.5882353 0.4117647 ## volkswagen 0.5925926 0.4074074 And if we want column proportions: prop.table(manuyear,2 ) ## ## 1999 2008 ## audi 0.076923077 0.076923077 ## chevrolet 0.059829060 0.102564103 ## dodge 0.136752137 0.179487179 ## ford 0.128205128 0.085470085 ## honda 0.042735043 0.034188034 ## hyundai 0.051282051 0.068376068 ## jeep 0.017094017 0.051282051 ## land rover 0.017094017 0.017094017 ## lincoln 0.017094017 0.008547009 ## mercury 0.017094017 0.017094017 ## nissan 0.051282051 0.059829060 ## pontiac 0.025641026 0.017094017 ## subaru 0.051282051 0.068376068 ## toyota 0.170940171 0.119658120 ## volkswagen 0.136752137 0.094017094 We can plot stuff, too. For example, hist does histograms: hist(mpg$displ, main=&quot;Engine displacement (in litres)&quot;, col=rainbow(20), xlim=c(0,10)) You can learn more about how to change the attributes of the plot with ?hist. We can create individual boxplots and boxplots grouped by values of categorical variables: boxplot(mpg$displ) boxplot(mpg$displ~mpg$manufacturer) These plots are created using the graphics library. There are other libraries that you can use to produce plots. One of them is ggplot2, which we installed earlier. A nice thing about ggplot2 is that it has the function qplot, which produces good-looking plots by default. For example: qplot(mpg$displ) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. qplot(mpg$manufacturer) qplot is smart enough to produce different plots depending on the type of the object. We’ll cover ggplot2 in more detail later in the semester. Exercise What is the maximum value of highway miles per gallon in the mpg dataset? How many cars with manual transmission are there in the mpg dataset? What % of the cars in the mpg dataset are SUVs? How many SUVs in the mpg dataset are 4-wheel drives? What is the % of Toyotas in the mpg dataset that are SUVs? (Not on TopHat) Create a barplot that shows how many cars are front-wheel drives, rear-wheel drives, and 4wd References Datacamp: introduction to R "],
["data-wrangling.html", "Chapter 2 Data wrangling 2.1 Importing and exporting data 2.2 Data subsetting 2.3 Missing data 2.4 Sorting data 2.5 Type conversions 2.6 Reformatting datasets 2.7 Merging and splitting References", " Chapter 2 Data wrangling 2.1 Importing and exporting data R can read data in many different formats and it has several functions that can help us with that. The functions themselves have numerous parameters and options that can be used to read messy data. I am not going to cover the ins and outs of that (it’s rather tedious). If you’re interested in learning more, I recommend this article. My personal workflow to importing data is (1) clean the data using some spreadsheet software (Excel, Numbers, Google Sheets) and then (2) read the spreadsheet using the “Import Dataset” option in RStudio (top-right corner). However, if the data are nicely formatted in *.csv or plain text format, using the functions read.csv and read.table is relatively painless. For example, you can read this dataset (hosted on my website) with the instruction depression = read.csv(&quot;http://vicpena.github.io/sta9750/fall18/depression.csv&quot;) If the dataset doesn’t have column names, you only need to add header = FALSE. For example, suppose that we want to read in this dataset, which is in plain text format. It doesn’t have variable names. We can read it in with femrole = read.table(&quot;http://users.stat.ufl.edu/~winner/data/femrole.dat&quot;, header=F) Exporting data with R is easy. If we want to export an existing data.frame to a *.csv file (which can be opened with Excel, Numbers, or any statistical package), we can use the function write.csv. For example, if we want to export the iris dataset into a file named iris.csv in the working directory: write.csv(iris, file = &quot;./iris.csv&quot;) If you want the file to be saved somewhere else, you can change ./ by any path you want. Another option is saving the workspace. That is, creating a file that has all the objects that we are currently working with (variables, data.frames, etc.). The function that allows us to do that is save. If we want to save all the variables and objects, we can simply type save(file='&lt;path&gt;/&lt;filename&gt;.RData'), where &lt;path&gt; is the path where the file will be saved and &lt;filename&gt; is the filename. We can also save only a subset of the variables. For example, suppose we want to save 2 objects named var1 and df. The command save(var1, df, file = '&lt;path&gt;/&lt;filename&gt;.RData') will do that for us. 2.2 Data subsetting In this section, we’ll cover how to subset variables and rows of datasets (mainly data.frames). We’ll cover 2 different ways of filtering. We’ll use the “traditional” way to do that (which doesn’t require any extra libraries) and we’ll use functions in library(dplyr) (which are faster in big datasets and more “intuitive”). 2.2.1 Subsetting variables We saw some of that in the previous chapter. Let’s load the iris dataset. data(&quot;iris&quot;) str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... If we want to create a subset that contains, say, the first, the second, and the fifth columns, it’s as easy as typing sub1 = iris[,c(1,2,5)] str(sub1) ## &#39;data.frame&#39;: 150 obs. of 3 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... We can also create subsets by specifying which columns we want to remove. For example, sub2 = iris[,-c(1,2,5)] str(sub2) ## &#39;data.frame&#39;: 150 obs. of 2 variables: ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... contains all the columns in except the first, the second, and the fifth. If we want to access specific columns of iris, we can use $ followed by the name of the variable. For example, if we want to take a look at Species: iris$Species ## [1] setosa setosa setosa setosa setosa setosa ## [7] setosa setosa setosa setosa setosa setosa ## [13] setosa setosa setosa setosa setosa setosa ## [19] setosa setosa setosa setosa setosa setosa ## [25] setosa setosa setosa setosa setosa setosa ## [31] setosa setosa setosa setosa setosa setosa ## [37] setosa setosa setosa setosa setosa setosa ## [43] setosa setosa setosa setosa setosa setosa ## [49] setosa setosa versicolor versicolor versicolor versicolor ## [55] versicolor versicolor versicolor versicolor versicolor versicolor ## [61] versicolor versicolor versicolor versicolor versicolor versicolor ## [67] versicolor versicolor versicolor versicolor versicolor versicolor ## [73] versicolor versicolor versicolor versicolor versicolor versicolor ## [79] versicolor versicolor versicolor versicolor versicolor versicolor ## [85] versicolor versicolor versicolor versicolor versicolor versicolor ## [91] versicolor versicolor versicolor versicolor versicolor versicolor ## [97] versicolor versicolor versicolor versicolor virginica virginica ## [103] virginica virginica virginica virginica virginica virginica ## [109] virginica virginica virginica virginica virginica virginica ## [115] virginica virginica virginica virginica virginica virginica ## [121] virginica virginica virginica virginica virginica virginica ## [127] virginica virginica virginica virginica virginica virginica ## [133] virginica virginica virginica virginica virginica virginica ## [139] virginica virginica virginica virginica virginica virginica ## [145] virginica virginica virginica virginica virginica virginica ## Levels: setosa versicolor virginica What we just covered is the traditional way of subsetting variables with R. With library(dplyr), we can use the command select. First, let’s load the library. library(dplyr) The following command creates a subset that contains the first, the second, and the fifth variables, sub3 = iris %&gt;% select(1,2,5) str(sub3) ## &#39;data.frame&#39;: 150 obs. of 3 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Note that there’s a %&gt;% separating iris and select. The operator %&gt;% is what we call a “pipe”. The commands in library(dplyr) (and library(tidyr), which we’ll also cover) can be concatenated using the pipe operator. It ends up being pretty convenient. It looks odd at first, but you’ll get used to it. A nice feature of select is that we can easily select variables using their names: sub4 = iris %&gt;% select(Sepal.Length, Sepal.Width, Species) head(sub4) ## Sepal.Length Sepal.Width Species ## 1 5.1 3.5 setosa ## 2 4.9 3.0 setosa ## 3 4.7 3.2 setosa ## 4 4.6 3.1 setosa ## 5 5.0 3.6 setosa ## 6 5.4 3.9 setosa As you can imagine, we can also create subsets by specifying which variables we want to exclude: sub5 = iris %&gt;% select(-c(1,2,5)) str(sub5) ## &#39;data.frame&#39;: 150 obs. of 2 variables: ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... sub6 = iris %&gt;% select(-c(Sepal.Length, Sepal.Width, Species)) str(sub6) ## &#39;data.frame&#39;: 150 obs. of 2 variables: ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... 2.2.2 Subsetting rows We can subset rows by indicating which row numbers we want to keep (or exclude). For example, we can create a subset with the first, the thirtieth, and the fiftieth observations in the iris dataset as follows sub1 = iris[c(1, 30, 50),] str(sub1) ## &#39;data.frame&#39;: 3 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.7 5 ## $ Sepal.Width : num 3.5 3.2 3.3 ## $ Petal.Length: num 1.4 1.6 1.4 ## $ Petal.Width : num 0.2 0.2 0.2 ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 And if we want to create a subset that includes all but the first, the thirtieth and the fiftieth observations: sub2 = iris[-c(1, 30, 50),] str(sub2) ## &#39;data.frame&#39;: 147 obs. of 5 variables: ## $ Sepal.Length: num 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 5.4 ... ## $ Sepal.Width : num 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 ... ## $ Petal.Length: num 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... This is alright, but not very useful in practice. We’re usually interested in subsets of rows that satisfy a certain condition. For example, we might be interested in creating a subset that only contains flowers of the setosa species. The following commands will do that for us cond1 = (iris$Species == &#39;setosa&#39;) str(cond1) ## logi [1:150] TRUE TRUE TRUE TRUE TRUE TRUE ... sub3 = iris[cond1,] str(sub3) ## &#39;data.frame&#39;: 50 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... In the first command, we create a logical type variable that takes on the value TRUE if Species is equal to setosa and FALSE otherwise (note that there are 2 equal signs between iris$Species and setosa). In the second command, we use the logical variable to filter the iris dataset. We can use a similar strategy to create all sorts of subsets according to logical conditions. The operators are ==: equal to !=: not equal to &gt;: greater than &lt;: less than &gt;=: greater or equal to &lt;=: less than or equal to For example, we can create a subset that contains only observations whose ngth is greater than 5 cond2 = (iris$Sepal.Length &gt; 5) sub4 = iris[cond2,] And we can create a subset that contain all the observations whose Species isn’t equal to setosa with either cond1 = (iris$Species == &#39;setosa&#39;) sub5 = iris[-cond1,] str(sub5) ## &#39;data.frame&#39;: 149 obs. of 5 variables: ## $ Sepal.Length: num 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 5.4 ... ## $ Sepal.Width : num 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 ... ## $ Petal.Length: num 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... cond3 = iris$Species != &#39;setosa&#39; sub6 = iris[-cond3,] str(sub6) ## &#39;data.frame&#39;: 149 obs. of 5 variables: ## $ Sepal.Length: num 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 5.4 ... ## $ Sepal.Width : num 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 ... ## $ Petal.Length: num 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Logical conditions can be combined with “and”, “or”, and “not” operators, which in R are: &amp;: and |: or !: not For example, we can create a subset that contains setosas whose Sepal.Length is greater than 5 with cond4 = (iris$Species == &#39;setosa&#39;)&amp;(iris$Sepal.Length &gt; 5) sub7 = iris[cond4,] str(sub7) ## &#39;data.frame&#39;: 22 obs. of 5 variables: ## $ Sepal.Length: num 5.1 5.4 5.4 5.8 5.7 5.4 5.1 5.7 5.1 5.4 ... ## $ Sepal.Width : num 3.5 3.9 3.7 4 4.4 3.9 3.5 3.8 3.8 3.4 ... ## $ Petal.Length: num 1.4 1.7 1.5 1.2 1.5 1.3 1.4 1.7 1.5 1.7 ... ## $ Petal.Width : num 0.2 0.4 0.2 0.2 0.4 0.4 0.3 0.3 0.3 0.2 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... We can create a subset that contains observations that are not setosas or whose Sepal.Width is less than or equal to 4 with cond5 = !(iris$Species == &#39;setosa&#39;)|(iris$Sepal.Width &lt;= 4) sub8 = iris[cond5,] str(sub8) ## &#39;data.frame&#39;: 147 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... We could’ve also written iris$Species != 'setosa'. What we just covered is the traditional way of subsetting rows with R. library(dplyr) has the function filter, which does the same thing with a cleaner syntax. For example, we can create a subset that contains setosas whose Sepal.Length is greater than 5 as follows sub1 = iris %&gt;% filter(Species == &#39;setosa&#39; &amp; Sepal.Length &gt; 5) And we can create a subset that contains flowers whose Species isn’t setosa or whose Sepal.Width is less than or equal to 4 sub2 = iris %&gt;% filter(Species != &#39;setosa&#39; | Sepal.Width &lt;= 4) As you can see, with filter we don’t have to type in iris$ whenever we want to specify a condition for a variables in iris. We can combine select and filter statements. For example, we can create a subset that excludes Species and only contains setosas as follows sub3 = iris %&gt;% filter(Species == &#39;setosa&#39;) %&gt;% select(-Species) str(sub3) ## &#39;data.frame&#39;: 50 obs. of 4 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... The order in which filter and select appear matters. If we typed the select statement first, we would get an error because when R tries to apply the filter, Species has already been excluded. ** Exercises on column and row subsetting, make them do summary statistics, count, etc. Rewrite missing values using filters ** 2.3 Missing data Sometimes our datasets have missing values. In R, missing values are marked as NA. For example, we can a vector with a missing value as follows x = c(1:5, NA) x ## [1] 1 2 3 4 5 NA When we have missing values, we have to be careful. For example, if we try to take the average of x with mean: mean(x) ## [1] NA In general, arithmetic operations with NAs return NAs: 0+NA ## [1] NA 3*NA ## [1] NA 5/NA ## [1] NA The function is.na can be used to filter missing values. For example, cond = is.na(x) cond ## [1] FALSE FALSE FALSE FALSE FALSE TRUE x = x[!cond] x ## [1] 1 2 3 4 5 For data.frames, the functions complete.cases and na.omit are useful. Let’s load the airquality dataset, which is built-in in `R``. data(airquality) The dataset has some air quality measurements that were taken in NYC from May to September in 1973 (see ?airquality for more details). The dataset has some missing values summary(airquality) ## Ozone Solar.R Wind Temp ## Min. : 1.00 Min. : 7.0 Min. : 1.700 Min. :56.00 ## 1st Qu.: 18.00 1st Qu.:115.8 1st Qu.: 7.400 1st Qu.:72.00 ## Median : 31.50 Median :205.0 Median : 9.700 Median :79.00 ## Mean : 42.13 Mean :185.9 Mean : 9.958 Mean :77.88 ## 3rd Qu.: 63.25 3rd Qu.:258.8 3rd Qu.:11.500 3rd Qu.:85.00 ## Max. :168.00 Max. :334.0 Max. :20.700 Max. :97.00 ## NA&#39;s :37 NA&#39;s :7 ## Month Day ## Min. :5.000 Min. : 1.0 ## 1st Qu.:6.000 1st Qu.: 8.0 ## Median :7.000 Median :16.0 ## Mean :6.993 Mean :15.8 ## 3rd Qu.:8.000 3rd Qu.:23.0 ## Max. :9.000 Max. :31.0 ## There are 37 missing Ozone readings and 7 missing values in Solar.R. The function complete.cases, when applied to airquality, will create a logical vector whose values will be TRUE if the observation is “complete” (i.e., doesn’t have any missing values) and FALSE if there is at least one variable with a missing value. We can create a new dataset called aircomp that only contains complete observations as follows aircomp = airquality[complete.cases(airquality),] The command above is equivalent to aircomp = na.omit(aircomp) We are covering complete.cases because having a logical vector can help us identify the observations that have missing values. Indeed, we can filter the observations that are NOT complete cases, that is: airquality[!complete.cases(airquality),] ## Ozone Solar.R Wind Temp Month Day ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 10 NA 194 8.6 69 5 10 ## 11 7 NA 6.9 74 5 11 ## 25 NA 66 16.6 57 5 25 ## 26 NA 266 14.9 58 5 26 ## 27 NA NA 8.0 57 5 27 ## 32 NA 286 8.6 78 6 1 ## 33 NA 287 9.7 74 6 2 ## 34 NA 242 16.1 67 6 3 ## 35 NA 186 9.2 84 6 4 ## 36 NA 220 8.6 85 6 5 ## 37 NA 264 14.3 79 6 6 ## 39 NA 273 6.9 87 6 8 ## 42 NA 259 10.9 93 6 11 ## 43 NA 250 9.2 92 6 12 ## 45 NA 332 13.8 80 6 14 ## 46 NA 322 11.5 79 6 15 ## 52 NA 150 6.3 77 6 21 ## 53 NA 59 1.7 76 6 22 ## 54 NA 91 4.6 76 6 23 ## 55 NA 250 6.3 76 6 24 ## 56 NA 135 8.0 75 6 25 ## 57 NA 127 8.0 78 6 26 ## 58 NA 47 10.3 73 6 27 ## 59 NA 98 11.5 80 6 28 ## 60 NA 31 14.9 77 6 29 ## 61 NA 138 8.0 83 6 30 ## 65 NA 101 10.9 84 7 4 ## 72 NA 139 8.6 82 7 11 ## 75 NA 291 14.9 91 7 14 ## 83 NA 258 9.7 81 7 22 ## 84 NA 295 11.5 82 7 23 ## 96 78 NA 6.9 86 8 4 ## 97 35 NA 7.4 85 8 5 ## 98 66 NA 4.6 87 8 6 ## 102 NA 222 8.6 92 8 10 ## 103 NA 137 11.5 86 8 11 ## 107 NA 64 11.5 79 8 15 ## 115 NA 255 12.6 75 8 23 ## 119 NA 153 5.7 88 8 27 ## 150 NA 145 13.2 77 9 27 2.4 Sorting data We can sort variables with the sort function. The default ordering is increasing. For example, sort(iris$Sepal.Length) ## [1] 4.3 4.4 4.4 4.4 4.5 4.6 4.6 4.6 4.6 4.7 4.7 4.8 4.8 4.8 4.8 4.8 4.9 ## [18] 4.9 4.9 4.9 4.9 4.9 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.1 5.1 ## [35] 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.2 5.2 5.2 5.2 5.3 5.4 5.4 5.4 5.4 5.4 ## [52] 5.4 5.5 5.5 5.5 5.5 5.5 5.5 5.5 5.6 5.6 5.6 5.6 5.6 5.6 5.7 5.7 5.7 ## [69] 5.7 5.7 5.7 5.7 5.7 5.8 5.8 5.8 5.8 5.8 5.8 5.8 5.9 5.9 5.9 6.0 6.0 ## [86] 6.0 6.0 6.0 6.0 6.1 6.1 6.1 6.1 6.1 6.1 6.2 6.2 6.2 6.2 6.3 6.3 6.3 ## [103] 6.3 6.3 6.3 6.3 6.3 6.3 6.4 6.4 6.4 6.4 6.4 6.4 6.4 6.5 6.5 6.5 6.5 ## [120] 6.5 6.6 6.6 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.8 6.8 6.8 6.9 6.9 6.9 ## [137] 6.9 7.0 7.1 7.2 7.2 7.2 7.3 7.4 7.6 7.7 7.7 7.7 7.7 7.9 sort(iris$Species) ## [1] setosa setosa setosa setosa setosa setosa ## [7] setosa setosa setosa setosa setosa setosa ## [13] setosa setosa setosa setosa setosa setosa ## [19] setosa setosa setosa setosa setosa setosa ## [25] setosa setosa setosa setosa setosa setosa ## [31] setosa setosa setosa setosa setosa setosa ## [37] setosa setosa setosa setosa setosa setosa ## [43] setosa setosa setosa setosa setosa setosa ## [49] setosa setosa versicolor versicolor versicolor versicolor ## [55] versicolor versicolor versicolor versicolor versicolor versicolor ## [61] versicolor versicolor versicolor versicolor versicolor versicolor ## [67] versicolor versicolor versicolor versicolor versicolor versicolor ## [73] versicolor versicolor versicolor versicolor versicolor versicolor ## [79] versicolor versicolor versicolor versicolor versicolor versicolor ## [85] versicolor versicolor versicolor versicolor versicolor versicolor ## [91] versicolor versicolor versicolor versicolor versicolor versicolor ## [97] versicolor versicolor versicolor versicolor virginica virginica ## [103] virginica virginica virginica virginica virginica virginica ## [109] virginica virginica virginica virginica virginica virginica ## [115] virginica virginica virginica virginica virginica virginica ## [121] virginica virginica virginica virginica virginica virginica ## [127] virginica virginica virginica virginica virginica virginica ## [133] virginica virginica virginica virginica virginica virginica ## [139] virginica virginica virginica virginica virginica virginica ## [145] virginica virginica virginica virginica virginica virginica ## Levels: setosa versicolor virginica If we want descending order, we can add the option decreasing = TRUE: sort(iris$Sepal.Length, decreasing = TRUE) ## [1] 7.9 7.7 7.7 7.7 7.7 7.6 7.4 7.3 7.2 7.2 7.2 7.1 7.0 6.9 6.9 6.9 6.9 ## [18] 6.8 6.8 6.8 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.7 6.6 6.6 6.5 6.5 6.5 6.5 ## [35] 6.5 6.4 6.4 6.4 6.4 6.4 6.4 6.4 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 6.3 ## [52] 6.2 6.2 6.2 6.2 6.1 6.1 6.1 6.1 6.1 6.1 6.0 6.0 6.0 6.0 6.0 6.0 5.9 ## [69] 5.9 5.9 5.8 5.8 5.8 5.8 5.8 5.8 5.8 5.7 5.7 5.7 5.7 5.7 5.7 5.7 5.7 ## [86] 5.6 5.6 5.6 5.6 5.6 5.6 5.5 5.5 5.5 5.5 5.5 5.5 5.5 5.4 5.4 5.4 5.4 ## [103] 5.4 5.4 5.3 5.2 5.2 5.2 5.2 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.0 ## [120] 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 4.9 4.9 4.9 4.9 4.9 4.9 4.8 4.8 ## [137] 4.8 4.8 4.8 4.7 4.7 4.6 4.6 4.6 4.6 4.5 4.4 4.4 4.4 4.3 This only works with variables. What if we want to order a data.frame according to the values of one of the variables? For that task, we can use order. For example, if we want to order iris in ascending order by Sepal.Length: head(iris[order(iris$Sepal.Length),]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 43 4.4 3.2 1.3 0.2 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 4 4.6 3.1 1.5 0.2 setosa I’m adding head() so that R doesn’t print the full dataset. If we want descending order instead: head(iris[order(-iris$Sepal.Length),]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 132 7.9 3.8 6.4 2.0 virginica ## 118 7.7 3.8 6.7 2.2 virginica ## 119 7.7 2.6 6.9 2.3 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 136 7.7 3.0 6.1 2.3 virginica ## 106 7.6 3.0 6.6 2.1 virginica When there are “ties”, we can also sort the data by a second variable. For example, if we sort the data in descending order by Species, there will be a lot of observations that will share the same value of Species. If, given the species, we want to sort in ascending order by Petal.Width, this will do that for us head(iris[order(-iris$Species, iris$Petal.Width),]) ## Warning in Ops.factor(iris$Species): &#39;-&#39; not meaningful for factors ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 10 4.9 3.1 1.5 0.1 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 33 5.2 4.1 1.5 0.1 setosa ## 38 4.9 3.6 1.4 0.1 setosa ## 1 5.1 3.5 1.4 0.2 setosa library(dplyr) has the function arrange, which is the analogue of order. The following piece of code sorts the dataset in ascending order by Sepal.Length head(iris %&gt;% arrange(Sepal.Length)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4.3 3.0 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3.0 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa If we want descending order head(iris %&gt;% arrange(desc(Sepal.Length))) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 7.9 3.8 6.4 2.0 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2.0 virginica ## 5 7.7 3.0 6.1 2.3 virginica ## 6 7.6 3.0 6.6 2.1 virginica And the following sorts in descending order by Species, and then in ascending order by Petal.Width. head(iris %&gt;% arrange(desc(Species), Petal.Width)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 6.1 2.6 5.6 1.4 virginica ## 2 6.0 2.2 5.0 1.5 virginica ## 3 6.3 2.8 5.1 1.5 virginica ## 4 7.2 3.0 5.8 1.6 virginica ## 5 4.9 2.5 4.5 1.7 virginica ## 6 6.3 2.9 5.6 1.8 virginica An advantage of using arrange is that we don’t have to type iris$&lt;variable name&gt; all the time. 2.5 Type conversions Oftentimes, categorical variables are coded as numerical. For example, let’s look at the dataset femrole.dat, which is uploaded on Professor Winner’s website. A description of the dataset can be found here and the data can be accessed here. As you can see, there are 4 categorical variables that are coded as numerical. How do we convert these variables to factors? The following instruction reads in the data femrole = read.table(&quot;http://users.stat.ufl.edu/~winner/data/femrole.dat&quot;, header = FALSE) Now, we can print it femrole ## V1 V2 V3 V4 V5 ## 1 1 1 1 1 11 ## 2 1 2 1 1 12 ## 3 2 1 1 1 10 ## 4 2 2 1 1 12 ## 5 1 1 1 2 13 ## 6 1 2 1 2 12 ## 7 2 1 1 2 8 ## 8 2 2 1 2 29 ## 9 1 1 2 1 11 ## 10 1 2 2 1 6 ## 11 2 1 2 1 4 ## 12 2 2 2 1 13 ## 13 1 1 2 2 17 ## 14 1 2 2 2 8 ## 15 2 1 2 2 9 ## 16 2 2 2 2 33 First of all, the columns don’t have interpretable names. We can change the names as follows: colnames(femrole) = c(&quot;personality&quot;, &quot;role&quot;, &quot;friends&quot;, &quot;dates&quot;, &quot;count&quot;) The variables personality, role, friends, and dates are categorical, but in femrole they are coded as numerical. To see this, we can run str(femrole) ## &#39;data.frame&#39;: 16 obs. of 5 variables: ## $ personality: int 1 1 2 2 1 1 2 2 1 1 ... ## $ role : int 1 2 1 2 1 2 1 2 1 2 ... ## $ friends : int 1 1 1 1 1 1 1 1 2 2 ... ## $ dates : int 1 1 1 1 2 2 2 2 1 1 ... ## $ count : int 11 12 10 12 13 12 8 29 11 6 ... The output tells us that personality, role, friends, dates, and count are of type int, which means that they’re coded as integers. The way that certain R functions treat variables depends on whether the variables are numerical or categorical. If we don’t convert the variables, we can get meaningless output. We can convert the variables to factors using as.factor: femrole$personality = as.factor(femrole$personality) femrole$role = as.factor(femrole$role) femrole$friends = as.factor(femrole$friends) femrole$dates = as.factor(femrole$dates) Let’s run str again: str(femrole) ## &#39;data.frame&#39;: 16 obs. of 5 variables: ## $ personality: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 2 2 1 1 2 2 1 1 ... ## $ role : Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 2 1 2 1 2 1 2 1 2 ... ## $ friends : Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 1 1 2 2 ... ## $ dates : Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 2 2 2 2 1 1 ... ## $ count : int 11 12 10 12 13 12 8 29 11 6 ... We have succesfully changed the type of the variables from integer to factor. However, the levels of the factors are noninformative. We can change them using levels: levels(femrole$personality) = c(&quot;Modern&quot;, &quot;Traditional&quot;) levels(femrole$role) = c(&quot;Modern&quot;, &quot;Traditional&quot;) levels(femrole$friends) = c(&quot;Low&quot;, &quot;High&quot;) levels(femrole$dates) = c(&quot;Low&quot;, &quot;High&quot;) ** Exercise ** Read in the dataset interfaith.dat, which is available on Professor Winner’s website or by clicking here (the description is available here). Change the variable names to something informative, convert the appropriate variables into factors, and rename the levels of the factors using meaningful labels. [Make them do 2 way tables and count frequencies and percentages] As you can imagine, other type conversions are possible. For instance, we can convert from matrix to data.frame with as.data.frame: mat = matrix(c(1,2,3,4,5,6), nrow = 3, ncol = 3) df = as.data.frame(mat) Now, df is of class data.frame: class(df) ## [1] &quot;data.frame&quot; We can also convert data.frames that contain numeric variables to matrix using as.matrix. df = data.frame(var1 = 1:3, var2 = 4:6) mat = as.matrix(df) And, unsurprisingly, class(mat) ## [1] &quot;matrix&quot; 2.6 Reformatting datasets 2.6.1 Aggregated data Let’s take a closer look at the femrole dataset, which we formatted in a previous section. femrole ## personality role friends dates count ## 1 Modern Modern Low Low 11 ## 2 Modern Traditional Low Low 12 ## 3 Traditional Modern Low Low 10 ## 4 Traditional Traditional Low Low 12 ## 5 Modern Modern Low High 13 ## 6 Modern Traditional Low High 12 ## 7 Traditional Modern Low High 8 ## 8 Traditional Traditional Low High 29 ## 9 Modern Modern High Low 11 ## 10 Modern Traditional High Low 6 ## 11 Traditional Modern High Low 4 ## 12 Traditional Traditional High Low 13 ## 13 Modern Modern High High 17 ## 14 Modern Traditional High High 8 ## 15 Traditional Modern High High 9 ## 16 Traditional Traditional High High 33 The data are aggregated: each row corresponds to a certain social profile. The last column counts how many observations there are for each profile. Unfortunately, R isn’t very good at working with data in this format. For example, suppose that we’re interested in knowing how many women in the dataset have a High number of dates. If we type in table(femrole$dates) ## ## Low High ## 8 8 we get the wrong answer. It’s not only tables: plots and statistical methods in R are coded in a way that makes working with aggregated data difficult. The most convenient format is a dataset where the rows correspond to different individuals (in this case, each row should correspond to a different woman). Thankfully, the function uncount in library(tidyr) makes the conversion easy. unaggregated = femrole %&gt;% uncount(count) The argument of uncount is the variable that contains the counts (which, in this case, is conveniently named count). If you want to convert individual data to an aggregated format, you can use the function count. Let’s create an object named indiv which contains the individual data: indiv = femrole %&gt;% uncount(count) We can convert the dataset into an aggregated format as follows: indiv %&gt;% count(personality, role, friends, dates) ## # A tibble: 16 x 5 ## personality role friends dates n ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Modern Modern Low Low 11 ## 2 Modern Modern Low High 13 ## 3 Modern Modern High Low 11 ## 4 Modern Modern High High 17 ## 5 Modern Traditional Low Low 12 ## 6 Modern Traditional Low High 12 ## 7 Modern Traditional High Low 6 ## 8 Modern Traditional High High 8 ## 9 Traditional Modern Low Low 10 ## 10 Traditional Modern Low High 8 ## 11 Traditional Modern High Low 4 ## 12 Traditional Modern High High 9 ## 13 Traditional Traditional Low Low 12 ## 14 Traditional Traditional Low High 29 ## 15 Traditional Traditional High Low 13 ## 16 Traditional Traditional High High 33 The arguments in count are the variables which we use for counting. For instance, compare the result above to indiv %&gt;% count(personality, dates) ## # A tibble: 4 x 3 ## personality dates n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Modern Low 40 ## 2 Modern High 50 ## 3 Traditional Low 39 ## 4 Traditional High 79 2.6.2 gather: from wide format to long format Suppose you want to compare outcomes with 3 treatments, and your data look like this wide ## # A tibble: 5 x 3 ## Treat1 Treat2 Treat3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1.60 0.983 -0.2 ## 2 0.409 -0.671 -0.022 ## 3 -0.019 -0.313 -1.74 ## 4 -0.251 3.25 1.88 ## 5 0.306 2.06 -0.083 Some people would say that the data is in “wide format.” Data in wide format aren’t convenient for running our analyses: if you want to run statistical methods or create plots, most R functions expect to have all the outcomes in one column, and the categories (treatments) in another column. This alternative formatting is called “long format”. You can go from wide to long format using gather in library(tidyr). data %&gt;% gather(key=treatment, value=outcome, Treat1, Treat2, Treat3) ## # A tibble: 15 x 2 ## treatment outcome ## &lt;chr&gt; &lt;dbl&gt; ## 1 Treat1 -1.60 ## 2 Treat1 0.409 ## 3 Treat1 -0.019 ## 4 Treat1 -0.251 ## 5 Treat1 0.306 ## 6 Treat2 0.983 ## 7 Treat2 -0.671 ## 8 Treat2 -0.313 ## 9 Treat2 3.25 ## 10 Treat2 2.06 ## 11 Treat3 -0.2 ## 12 Treat3 -0.022 ## 13 Treat3 -1.74 ## 14 Treat3 1.88 ## 15 Treat3 -0.083 The first argument in gather is for naming the new column that contains the categories (the key), the second one is for naming the column where the new outcomes will be stored (the value), and then you write the names of the columns that contain the outcomes you want to gather. An equivalent way of writing the same thing is: data %&gt;% gather(key=treatment, value=outcome, Treat1:Treat3) ## # A tibble: 15 x 2 ## treatment outcome ## &lt;chr&gt; &lt;dbl&gt; ## 1 Treat1 -1.60 ## 2 Treat1 0.409 ## 3 Treat1 -0.019 ## 4 Treat1 -0.251 ## 5 Treat1 0.306 ## 6 Treat2 0.983 ## 7 Treat2 -0.671 ## 8 Treat2 -0.313 ## 9 Treat2 3.25 ## 10 Treat2 2.06 ## 11 Treat3 -0.2 ## 12 Treat3 -0.022 ## 13 Treat3 -1.74 ## 14 Treat3 1.88 ## 15 Treat3 -0.083 In Treat1:Treat3 we gave R a range of columns which we want to gather (first to last). This is useful if you have many variables. What if your data is in wide format, but you have an uneven number of observations? That is, your data looks something like this uneven ## # A tibble: 5 x 3 ## Treat1 Treat2 Treat3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1.60 0.983 -0.2 ## 2 0.409 -0.671 -0.022 ## 3 -0.019 -0.313 -1.74 ## 4 -0.251 3.25 NA ## 5 NA 2.06 NA Let’s try to gather: uneven %&gt;% gather(key = treatment, value = outcome, Treat1:Treat3) ## # A tibble: 15 x 2 ## treatment outcome ## &lt;chr&gt; &lt;dbl&gt; ## 1 Treat1 -1.60 ## 2 Treat1 0.409 ## 3 Treat1 -0.019 ## 4 Treat1 -0.251 ## 5 Treat1 NA ## 6 Treat2 0.983 ## 7 Treat2 -0.671 ## 8 Treat2 -0.313 ## 9 Treat2 3.25 ## 10 Treat2 2.06 ## 11 Treat3 -0.2 ## 12 Treat3 -0.022 ## 13 Treat3 -1.74 ## 14 Treat3 NA ## 15 Treat3 NA Unfortunately, we get some NAs. We can get rid of them with na.omit: uneven %&gt;% gather(key = treatment, value = outcome, Treat1:Treat3) %&gt;% na.omit ## # A tibble: 12 x 2 ## treatment outcome ## &lt;chr&gt; &lt;dbl&gt; ## 1 Treat1 -1.60 ## 2 Treat1 0.409 ## 3 Treat1 -0.019 ## 4 Treat1 -0.251 ## 5 Treat2 0.983 ## 6 Treat2 -0.671 ## 7 Treat2 -0.313 ## 8 Treat2 3.25 ## 9 Treat2 2.06 ## 10 Treat3 -0.2 ## 11 Treat3 -0.022 ## 12 Treat3 -1.74 2.6.3 spread: from long to wide format If you want to go from long to wide format, you can use spread. For example, if your data are data2 ## # A tibble: 15 x 3 ## # Groups: treatment [3] ## treatment outcome ind ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Treat1 -1.60 1 ## 2 Treat1 0.409 2 ## 3 Treat1 -0.019 3 ## 4 Treat1 -0.251 4 ## 5 Treat1 0.306 5 ## 6 Treat2 0.983 1 ## 7 Treat2 -0.671 2 ## 8 Treat2 -0.313 3 ## 9 Treat2 3.25 4 ## 10 Treat2 2.06 5 ## 11 Treat3 -0.2 1 ## 12 Treat3 -0.022 2 ## 13 Treat3 -1.74 3 ## 14 Treat3 1.88 4 ## 15 Treat3 -0.083 5 You can convert it to wide format as follows data2 %&gt;% spread(treatment, outcome) ## # A tibble: 5 x 4 ## ind Treat1 Treat2 Treat3 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 -1.60 0.983 -0.2 ## 2 2 0.409 -0.671 -0.022 ## 3 3 -0.019 -0.313 -1.74 ## 4 4 -0.251 3.25 1.88 ## 5 5 0.306 2.06 -0.083 Note that data2 isn’t just our dataset that came out of gathering. In fact, if you start with gath = data %&gt;% gather(key=treatment, value=outcome, Treat1:Treat3) and you try to spread, you’ll get an error. R complains because the rows of gath aren’t uniquely identifiable. A way to get around that is creating index variables within the treatments gath = gath %&gt;% group_by(treatment) %&gt;% mutate(id=row_number()) gath ## # A tibble: 15 x 3 ## # Groups: treatment [3] ## treatment outcome id ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Treat1 -1.60 1 ## 2 Treat1 0.409 2 ## 3 Treat1 -0.019 3 ## 4 Treat1 -0.251 4 ## 5 Treat1 0.306 5 ## 6 Treat2 0.983 1 ## 7 Treat2 -0.671 2 ## 8 Treat2 -0.313 3 ## 9 Treat2 3.25 4 ## 10 Treat2 2.06 5 ## 11 Treat3 -0.2 1 ## 12 Treat3 -0.022 2 ## 13 Treat3 -1.74 3 ## 14 Treat3 1.88 4 ## 15 Treat3 -0.083 5 and then, you can spread (and get rid of id): gath %&gt;% spread(treatment, outcome) %&gt;% select(-id) ## # A tibble: 5 x 3 ## Treat1 Treat2 Treat3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1.60 0.983 -0.2 ## 2 0.409 -0.671 -0.022 ## 3 -0.019 -0.313 -1.74 ## 4 -0.251 3.25 1.88 ## 5 0.306 2.06 -0.083 2.6.4 Creating and renaming variables [Add rename()] and old R ways of doing this We can use mutate if we want to transform/create new variables. For example, if we want to create a new variable called avg which contains the average schore in read, write, science, and socst: hsb2 = hsb2 %&gt;% mutate(avg=(read+write+science+socst)/4) 2.6.5 Obtaining summaries by categories of variables We can create objects which contain summaries for different groups by combining group_by and summarize: hsb2 %&gt;% group_by(race) %&gt;% summarize(medMath = median(math), sdMath = sd(math)) ## # A tibble: 4 x 3 ## race medMath sdMath ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 african american 45 6.49 ## 2 asian 61 10.1 ## 3 hispanic 47 6.98 ## 4 white 54 9.38 And you can combine these function with the other functions we learned today. For example: hsb2 %&gt;% group_by(race) %&gt;% filter(math &gt; 70) %&gt;% summarize(n=n()) ## # A tibble: 2 x 2 ## race n ## &lt;fct&gt; &lt;int&gt; ## 1 asian 1 ## 2 white 9 Tells us that there are 10 people who got a math score greater than 70, and that 1 of them is asian and 9 of them are white. 2.7 Merging and splitting 2.7.1 Merging and splitting variables Suppose you have the following dataset drinks ## # A tibble: 6 x 3 ## spirit mixer total ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 gin tonic 8 ## 2 sparkling wine orange juice 6 ## 3 rum coke 7 ## 4 red wine coke 5 ## 5 &lt;NA&gt; seltzer 5 ## 6 beer &lt;NA&gt; 5 If you would like to create a new column that merges the information in spirit and mixer, you can use the command unite. For example, you can try drinks %&gt;% unite(name, spirit, mixer, sep=&#39; &amp; &#39;) ## # A tibble: 6 x 2 ## name total ## &lt;chr&gt; &lt;dbl&gt; ## 1 gin &amp; tonic 8 ## 2 sparkling wine &amp; orange juice 6 ## 3 rum &amp; coke 7 ## 4 red wine &amp; coke 5 ## 5 NA &amp; seltzer 5 ## 6 beer &amp; NA 5 Unfortunately, it doesn’t look great because there are NAs. You can substitute the NAs by nothing using coalesce to make the output look a little nicer: new = drinks %&gt;% mutate(spirit=coalesce(spirit, &quot;nothing&quot;), mixer=coalesce(mixer, &quot;nothing&quot;)) %&gt;% unite(name, spirit, mixer, sep=&#39; &amp; &#39;) %&gt;% mutate(name=trimws(name)) new ## # A tibble: 6 x 2 ## name total ## &lt;chr&gt; &lt;dbl&gt; ## 1 gin &amp; tonic 8 ## 2 sparkling wine &amp; orange juice 6 ## 3 rum &amp; coke 7 ## 4 red wine &amp; coke 5 ## 5 nothing &amp; seltzer 5 ## 6 beer &amp; nothing 5 The function trimws got rid of some empty spaces at the beginning and end of name. If you are willing to work a little bit more, you can make the new variable look even nicer: final = new %&gt;% mutate(name1 = gsub(&quot;&amp; nothing&quot;,&quot;&quot;,name), name = trimws(gsub(&quot;nothing &amp;&quot;,&quot;&quot;,name1))) %&gt;% select(-name1) final ## # A tibble: 6 x 2 ## name total ## &lt;chr&gt; &lt;dbl&gt; ## 1 gin &amp; tonic 8 ## 2 sparkling wine &amp; orange juice 6 ## 3 rum &amp; coke 7 ## 4 red wine &amp; coke 5 ## 5 seltzer 5 ## 6 beer 5 We used the function gsub to substitute &amp; nothing and nothing &amp; by (literally) nothing. You can split up variables using separate. For example, if you start with ## # A tibble: 6 x 2 ## name total ## &lt;chr&gt; &lt;dbl&gt; ## 1 gin &amp; tonic 8 ## 2 sparkling wine &amp; orange juice 6 ## 3 rum &amp; coke 7 ## 4 red wine &amp; coke 5 ## 5 nothing &amp; seltzer 5 ## 6 beer &amp; nothing 5 We can split up name into spirit and mixer with new %&gt;% separate(name, into=c(&quot;spirit&quot;, &quot;mixer&quot;), sep=&quot; &amp; &quot;) ## # A tibble: 6 x 3 ## spirit mixer total ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 gin tonic 8 ## 2 sparkling wine orange juice 6 ## 3 rum coke 7 ## 4 red wine coke 5 ## 5 nothing seltzer 5 ## 6 beer nothing 5 If you use the dataset final instead, you would have to do more work to separate correctly. 2.7.2 Merging and splitting data In lecture, we learned about left_join, right_join, inner_join, and full_join. Our starting point is 2 datasets a and b, which have a variable in common named x. We wish to merge the datasets by matching values of x. left_join(a, b, by='x'): Keep all the rows in a, find rows in dataset b that have matching values of x in a, and include the extra columns in b that don’t appear in a. Don’t include rows in b that have no matching value of x in b. right_join(a, b, by='x'): Keep all the rows in b, find rows in dataset a that have matching values of x in b, and include the extra columns in a that don’t appear in b. Don’t include rows in a that have no matching value of x in b. inner_join(a, b, by='x'): Keep rows that have values of x that appear in both a and b. full_join(a, b, by='x'): Keep all the rows in a and b, even if they don’t have matching values in x. To make this concrete, let’s work with a specific example. The tibbles below contain names of drinks: nonalcoholic = tibble(name=c(&quot;g&amp;t&quot;,&quot;mimosa&quot;,&quot;rum and coke&quot;,&quot;calimocho&quot;,&quot;polar&quot;), mixer=c(&quot;tonic&quot;,&quot;orange juice&quot;, &quot;coke&quot;, &quot;coke&quot;,&quot;seltzer&quot;)) alcoholic = tibble(name=c(&quot;g&amp;t&quot;,&quot;mimosa&quot;,&quot;rum and coke&quot;,&quot;calimocho&quot;,&quot;IPA&quot;,&quot;dark and stormy&quot;), spirit=c(&quot;gin&quot;,&quot;sparkling wine&quot;, &quot;rum&quot;, &quot;red wine&quot;,&quot;beer&quot;,&quot;rum&quot;)) Let’s try out what happens when we try the different joins on the tibbles: left_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 5 x 3 ## name mixer spirit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 g&amp;t tonic gin ## 2 mimosa orange juice sparkling wine ## 3 rum and coke coke rum ## 4 calimocho coke red wine ## 5 polar seltzer &lt;NA&gt; right_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 6 x 3 ## name mixer spirit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 g&amp;t tonic gin ## 2 mimosa orange juice sparkling wine ## 3 rum and coke coke rum ## 4 calimocho coke red wine ## 5 IPA &lt;NA&gt; beer ## 6 dark and stormy &lt;NA&gt; rum inner_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 4 x 3 ## name mixer spirit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 g&amp;t tonic gin ## 2 mimosa orange juice sparkling wine ## 3 rum and coke coke rum ## 4 calimocho coke red wine full_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 7 x 3 ## name mixer spirit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 g&amp;t tonic gin ## 2 mimosa orange juice sparkling wine ## 3 rum and coke coke rum ## 4 calimocho coke red wine ## 5 polar seltzer &lt;NA&gt; ## 6 IPA &lt;NA&gt; beer ## 7 dark and stormy &lt;NA&gt; rum We can also use joins for filtering. For example, semi_join(a, b, by='x') keeps all the rows in a that have a matching value of x in b (it doesn’t create more columns with the information in b), and anti_join(a, b, by='x') keeps the rows in a that don’t have a matching value of x in b: semi_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 4 x 2 ## name mixer ## &lt;chr&gt; &lt;chr&gt; ## 1 g&amp;t tonic ## 2 mimosa orange juice ## 3 rum and coke coke ## 4 calimocho coke anti_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 1 x 2 ## name mixer ## &lt;chr&gt; &lt;chr&gt; ## 1 polar seltzer Suppose we get prices for the drinks: nonalcoholic = nonalcoholic %&gt;% mutate(price=c(8, 6, 7, 5, 5)) alcoholic = alcoholic %&gt;% mutate(&#39;$&#39;=c(8, 6, 7, 5, 5, NA)) How can we join the new tibbles nicely? First, we can rename the price variable in alcoholic: alcoholic = alcoholic %&gt;% rename(price=&#39;$&#39;) And then, we can full_join the tibbles by their name and price (we want a double match): join = full_join(nonalcoholic, alcoholic, by=c(&#39;name&#39;,&#39;price&#39;)) join ## # A tibble: 7 x 4 ## name mixer price spirit ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 g&amp;t tonic 8 gin ## 2 mimosa orange juice 6 sparkling wine ## 3 rum and coke coke 7 rum ## 4 calimocho coke 5 red wine ## 5 polar seltzer 5 &lt;NA&gt; ## 6 IPA &lt;NA&gt; 5 beer ## 7 dark and stormy &lt;NA&gt; NA rum If we want to reorder the columns so that the spirit comes first, followed by the mixer, we can use select: join = join %&gt;% select(name, spirit, mixer, price) join ## # A tibble: 7 x 4 ## name spirit mixer price ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic 8 ## 2 mimosa sparkling wine orange juice 6 ## 3 rum and coke rum coke 7 ## 4 calimocho red wine coke 5 ## 5 polar &lt;NA&gt; seltzer 5 ## 6 IPA beer &lt;NA&gt; 5 ## 7 dark and stormy rum &lt;NA&gt; NA Now, suppose we got a new tibble with the extra components that were missing for dark and stormy ds = tibble(name=&#39;dark and stormy&#39;, spirit=&#39;ginger beer&#39;, price = 8) How can we incorporate this new information? We can start by full_joining full_join(join, ds, by=&#39;name&#39;) ## # A tibble: 7 x 6 ## name spirit.x mixer price.x spirit.y price.y ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic 8 &lt;NA&gt; NA ## 2 mimosa sparkling wine orange juice 6 &lt;NA&gt; NA ## 3 rum and coke rum coke 7 &lt;NA&gt; NA ## 4 calimocho red wine coke 5 &lt;NA&gt; NA ## 5 polar &lt;NA&gt; seltzer 5 &lt;NA&gt; NA ## 6 IPA beer &lt;NA&gt; 5 &lt;NA&gt; NA ## 7 dark and stormy rum &lt;NA&gt; NA ginger beer 8 This join has a few problems. We’d like to combine price.x and price.y. We can do that using the function coalesce, and then getting rid of price.x and price.y: full_join(join, ds, by=&#39;name&#39;) %&gt;% mutate(price=coalesce(price.x,price.y)) %&gt;% select(-price.x, -price.y) ## # A tibble: 7 x 5 ## name spirit.x mixer spirit.y price ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic &lt;NA&gt; 8 ## 2 mimosa sparkling wine orange juice &lt;NA&gt; 6 ## 3 rum and coke rum coke &lt;NA&gt; 7 ## 4 calimocho red wine coke &lt;NA&gt; 5 ## 5 polar &lt;NA&gt; seltzer &lt;NA&gt; 5 ## 6 IPA beer &lt;NA&gt; &lt;NA&gt; 5 ## 7 dark and stormy rum &lt;NA&gt; ginger beer 8 This is mostly fine. If we want to combine spirit.x and spirit.y: full_join(join, ds, by=&#39;name&#39;) %&gt;% mutate(price=coalesce(price.x,price.y)) %&gt;% select(-price.x, -price.y) %&gt;% replace(is.na(.),&quot;&quot;) %&gt;% unite(spirit, spirit.x, spirit.y, sep=&quot;&quot;) ## # A tibble: 7 x 4 ## name spirit mixer price ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic 8 ## 2 mimosa sparkling wine orange juice 6 ## 3 rum and coke rum coke 7 ## 4 calimocho red wine coke 5 ## 5 polar &quot;&quot; seltzer 5 ## 6 IPA beer &quot;&quot; 5 ## 7 dark and stormy rumginger beer &quot;&quot; 8 First, we replaced the NAs by empty spaces, and then we joined the variables spirit.x, and spirit.y using unite. The formatting isn’t great, unforunately. We can play around a little bit to make it look nicer: ds = ds %&gt;% mutate(spirit=paste(&quot; &quot;, spirit,sep=&quot;&quot;)) final = full_join(join, ds, by=&#39;name&#39;) %&gt;% mutate(price=coalesce(price.x,price.y)) %&gt;% select(-price.x, -price.y) %&gt;% replace(is.na(.),&quot;&quot;) %&gt;% unite(spirit, spirit.x, spirit.y, sep=&quot;&quot;) final ## # A tibble: 7 x 4 ## name spirit mixer price ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic 8 ## 2 mimosa sparkling wine orange juice 6 ## 3 rum and coke rum coke 7 ## 4 calimocho red wine coke 5 ## 5 polar &quot;&quot; seltzer 5 ## 6 IPA beer &quot;&quot; 5 ## 7 dark and stormy rum ginger beer &quot;&quot; 8 Now suppose that we’re at some bar where the total price for a mixed drink is equal to the sum of the prices of the components. The prices are nonalcoholic = tibble(name=c(&quot;g&amp;t&quot;,&quot;mimosa&quot;,&quot;rum and coke&quot;,&quot;calimocho&quot;,&quot;polar&quot;), mixer=c(&quot;tonic&quot;,&quot;orange juice&quot;, &quot;coke&quot;, &quot;coke&quot;,&quot;seltzer&quot;)) %&gt;% mutate(price=c(3, 2, 2, 2, 5)) alcoholic = tibble(name=c(&quot;g&amp;t&quot;,&quot;mimosa&quot;,&quot;rum and coke&quot;,&quot;calimocho&quot;,&quot;IPA&quot;), spirit=c(&quot;gin&quot;,&quot;sparkling wine&quot;, &quot;rum&quot;, &quot;red wine&quot;,&quot;beer&quot;)) %&gt;% mutate(price=c(5, 4, 5, 3, 5)) How can we merge the data and combine (add) prices? We can start by full_joining by name full_join(nonalcoholic, alcoholic, by=&#39;name&#39;) ## # A tibble: 6 x 5 ## name mixer price.x spirit price.y ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t tonic 3 gin 5 ## 2 mimosa orange juice 2 sparkling wine 4 ## 3 rum and coke coke 2 rum 5 ## 4 calimocho coke 2 red wine 3 ## 5 polar seltzer 5 &lt;NA&gt; NA ## 6 IPA &lt;NA&gt; NA beer 5 Unfortunately, a simple mutate instruction isn’t satisfactory because the sum of an NA + a number is equal to NA: full_join(nonalcoholic, alcoholic, by=&#39;name&#39;) %&gt;% mutate(total=price.x+price.y) ## # A tibble: 6 x 6 ## name mixer price.x spirit price.y total ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 g&amp;t tonic 3 gin 5 8 ## 2 mimosa orange juice 2 sparkling wine 4 6 ## 3 rum and coke coke 2 rum 5 7 ## 4 calimocho coke 2 red wine 3 5 ## 5 polar seltzer 5 &lt;NA&gt; NA NA ## 6 IPA &lt;NA&gt; NA beer 5 NA We can solve this problem in different ways. One way is using coalesce to replace the NAs by zeros in price.x and price.y, and then adding: full_join(nonalcoholic, alcoholic, by=&#39;name&#39;) %&gt;% mutate(price.x=coalesce(price.x,0), price.y=coalesce(price.y,0), total=price.x+price.y) %&gt;% select(name, spirit, mixer, total) ## # A tibble: 6 x 4 ## name spirit mixer total ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 g&amp;t gin tonic 8 ## 2 mimosa sparkling wine orange juice 6 ## 3 rum and coke rum coke 7 ## 4 calimocho red wine coke 5 ## 5 polar &lt;NA&gt; seltzer 5 ## 6 IPA beer &lt;NA&gt; 5 In general, the way that R deals with NAs can be a little frustrating, as these examples show. 2.7.3 Set operations and binding Source: Data wrangling cheat sheet Consider the tibbles y and z, which have matching variable names x1 and x2 (this is important!): y ## # A tibble: 3 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 z ## # A tibble: 3 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 B 2 ## 2 C 3 ## 3 D 4 Set operations intersect(y,z): find rows that appear in both y and z intersect(y,z) ## # A tibble: 2 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 B 2 ## 2 C 3 union(y,z): find rows that appear in y or z (or both): union(y,z) ## # A tibble: 4 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 D 4 ## 2 C 3 ## 3 B 2 ## 4 A 1 setdiff(y, z): find rows that appear in y but not in z: setdiff(y,z) ## # A tibble: 1 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 Binding rows and columns If you want to bind the rows of y and z bind_rows(y,z) ## # A tibble: 6 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 B 2 ## 5 C 3 ## 6 D 4 If you want to bind the columns of y and z: bind_cols(y,z) ## # A tibble: 3 x 4 ## x1 x2 x11 x21 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 A 1 B 2 ## 2 B 2 C 3 ## 3 C 3 D 4 References dplyr cheat sheet tidyr website Tutorial by Bradley Boehmke Tutorial by Olivia L. Holmes Chapter 12 of R Programming for Data Science, by Roger D. Peng "],
["data-visualization-with-ggplot2.html", "Chapter 3 Data visualization with ggplot2 3.1 Basic plots with qplot 3.2 Axes, titles and labels 3.3 More qplot 3.4 More ggplot 3.5 Axes, titles and labels References", " Chapter 3 Data visualization with ggplot2 In this chapter, we’ll learn the basics of ggplot2. There are many good resources on the topic. Some of them are: Cookbook for R ggplot2 cheatsheet r-statistics.co We will use the diamonds dataset in library(ggplot2), so we load the library and the dataset. library(ggplot2) data(diamonds) The dataset has 53940 observations and 10 columns, with column names ## [1] &quot;carat&quot; &quot;cut&quot; &quot;color&quot; &quot;clarity&quot; &quot;depth&quot; &quot;table&quot; &quot;price&quot; ## [8] &quot;x&quot; &quot;y&quot; &quot;z&quot; You can get more information on what the variables are by running the R command ?diamonds 3.1 Basic plots with qplot We have seen how to create some basic plots with qplot already. Now it’s time to summarize what we learned and go a little deeper. The good thing about qplot is that it has good defaults for a decent amount of situations. 3.1.1 Univariate plots One variable at a time! 3.1.1.1 Categorical The most common plots for univariate categorical data are pie charts and bar plots. People who have done research on data visualization agree that pie charts are bad. For example, if you get help for the function pie (which produces pie charts in the base graphics library on R), you get the following note: Pie charts are a very bad way of displaying information. The eye is good at judging linear measures and bad at judging relative areas. A bar chart or dot chart is a preferable way of displaying this type of data. Cleveland (1985), page 264: “Data that can be shown by pie charts always can be shown by a dot chart. This means that judgements of position along a common scale can be made instead of the less accurate angle judgements.” This statement is based on the empirical investigations of Cleveland and McGill as well as investigations by perceptual psychologists. It’s possible to create pie charts with ggplot2 (see e.g. this link) but we won’t cover them here. Creating a bar plot with qplot is very easy: qplot(cut, data=diamonds) In ggplot2, plots can be saved as variables. This is a useful feature because, in ggplot2, we create visualizations sequentially by adding layers to a plot. It also makes the code cleaner. Let’s save the plot in a variable and add stuff to it. barcut = qplot(cut, data=diamonds) Sometimes I feel like the default fontsize of the plots is too small. You can change the font size as follows barcut = barcut+theme(text=element_text(size=15)) barcut You can change the color of the bars: barcut = barcut+geom_bar(fill=&#39;steelblue&#39;) barcut And you can flip the coordinates barcut = barcut+coord_flip() barcut You can add a title, too! barcut = barcut+ggtitle(&quot;Quality of cut&quot;) barcut If you want to center the title: barcut + theme(plot.title = element_text(hjust = 0.5)) As you saw, since we were saving the changes as we produced them, all the previous changes to the plot were saved. As you might imagine, an equivalent chunk of code to produce the plot is qplot(cut, data=diamonds)+ theme(text=element_text(size=15))+ geom_bar(fill=&#39;steelblue&#39;)+ coord_flip()+ ggtitle(&quot;Quality of cut&quot;)+ theme(plot.title = element_text(hjust = 0.5)) You can change the general theme quite easily as well: qplot(cut, data=diamonds)+theme_minimal() You can find a list of default themes here. You’ll have access to more themes if you install library(ggthemes). See this reference for more details. 3.1.1.2 Quantitative In qplot, the default plot for quantitative data looks like this qplot(price,data=diamonds) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. You can also make density plots. qplot(price, geom=&#39;density&#39;, data=diamonds) You can change the color of the density plot as follows: qplot(price, geom=&#39;density&#39;, data=diamonds) + geom_density(fill=&#39;steelblue&#39;) 3.1.2 Bivariate 3.1.2.1 Categorical vs Categorical Creating stacked barplots is easy. q1 = qplot(x=cut, fill=color, data=diamonds) q1 Alternatively, q2 = qplot(x=color, fill=cut, data=diamonds) q2 You can play around with the color palette with scale_fill_brewer. q2 + scale_fill_brewer(palette=&quot;Spectral&quot;) More info here and here. Exercise How would you flip the coordinates? Solution q2 + coord_flip() Exercise Does the distribution of colors depend on the quality of the cut? Solution We can answer this question with a \\(\\chi^2\\)-test. tab = table(diamonds$color, diamonds$cut) round(prop.table(tab,1),2) ## ## Fair Good Very Good Premium Ideal ## D 0.02 0.10 0.22 0.24 0.42 ## E 0.02 0.10 0.24 0.24 0.40 ## F 0.03 0.10 0.23 0.24 0.40 ## G 0.03 0.08 0.20 0.26 0.43 ## H 0.04 0.08 0.22 0.28 0.38 ## I 0.03 0.10 0.22 0.26 0.39 ## J 0.04 0.11 0.24 0.29 0.32 round(prop.table(tab,2),2) ## ## Fair Good Very Good Premium Ideal ## D 0.10 0.13 0.13 0.12 0.13 ## E 0.14 0.19 0.20 0.17 0.18 ## F 0.19 0.19 0.18 0.17 0.18 ## G 0.20 0.18 0.19 0.21 0.23 ## H 0.19 0.14 0.15 0.17 0.14 ## I 0.11 0.11 0.10 0.10 0.10 ## J 0.07 0.06 0.06 0.06 0.04 chisq.test(tab) ## ## Pearson&#39;s Chi-squared test ## ## data: tab ## X-squared = 310.32, df = 24, p-value &lt; 2.2e-16 3.1.2.2 Categorical vs Quantitative Different options here! But some of them are bad. For example, I think this is a bad plot: qplot(x=price, fill=cut, data=diamonds) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. How can we create a better plot? A less bad plot is qplot(x=price, color=cut, geom=&#39;density&#39;, data=diamonds) Side-by-side boxplots are a better alternative: qplot(x=cut, y=price, geom=&#39;boxplot&#39;, data=diamonds)+coord_flip() You can add color using fill: qplot(x=cut, y=price, fill=cut, geom=&#39;boxplot&#39;, data=diamonds)+ theme(legend.position=&quot;none&quot;)+ coord_flip() The code theme(legend.position=&quot;none&quot;) gets rid of the legend. Another option is using facets. qplot(price, facets = cut ~ ., data=diamonds) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 3.1.2.3 Quantitative vs Quantitative Scatterplots are your best bet here. qplot(x=carat, y=price, data=diamonds) You can add some smoothed trend: qplot(x=carat, y=price, data=diamonds)+geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; And you can fit some linear trend: qplot(x=carat, y=price, data=diamonds)+geom_smooth(method=&#39;lm&#39;) Exercise Can we use transformations to make the linear fit better? Solution Yes, if you take logs of both variables, it’ll look better. There are still some patches which are probably due to the existence of some hidden variable(s). The variance doesn’t seem to be constant. qplot(x=log(carat), y=log(price), data=diamonds)+geom_smooth(method=&#39;lm&#39;) 3.2 Axes, titles and labels The relevant commands here are ggtitle: for changing the title xlab, ylab: \\(x\\) and \\(y\\) labels xlim, ylim: limits / scale of the plot qplot(x=carat, y=price, data=diamonds)+ xlab(&quot;carat (weight)&quot;) + ylab(&quot;price ($)&quot;) + ggtitle(&quot;Price vs carat&quot;) + xlim(c(0,10))+ ylim(c(0,30000)) 3.3 More qplot 3.3.1 More than 2 variables at once We can create scatterplots with colored dots of different shapes: qplot(x=carat, y=price, color=cut, shape=cut, data=diamonds) ## Warning: Using shapes for an ordinal variable is not advised We can plot colored smoothed curves (potentially overlaid on points; not recommended, though). qplot(x=carat, y=price, color=cut, geom=&#39;smooth&#39;, data=diamonds)+geom_point(alpha=0.02) ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; We can plot panels with colored dots: qplot(x=carat, y=price, color=cut, facets=color ~ ., data=diamonds) Double panels! qplot(x=carat, y=price, facets=color~cut, data=diamonds) Double panels of colored dots… [Q: how many variables are we plotting at once now?] qplot(x=carat, y=price, color=clarity, facets=color~cut, data=diamonds) We could redo all of these with smooth curves/lines instead. How can we plot relationships between 3 numerical/quantitative variables? This is one option qplot(x=depth, y=carat, color=price, data=diamonds) Another option is categorizing one of the variables, and then plotting bivariate relationships in panels. Below we partition the variable depth into 4 categories (defined by its quartiles): diamonds$depthcat = cut(diamonds$depth, breaks=quantile(diamonds$depth), include.lowest = TRUE) qplot(x=carat, y=price, facets=.~depthcat, data=diamonds) 3.3.2 grid.arrange Sometimes it’s useful to have unrelated plots in one panel. Exercise With the base graphics package, we can do that with par(mfrow=c( , )). For example, if we want a plot that has 2 rows, one with a histogram of price and another row which has a bar plot of cut, how would we do that? Answer par(mfrow=c(2,1)) hist(diamonds$price) plot(diamonds$cut) Unfortunately, par(mfrow=c(,)) doesn’t work with ggplot. Fortunately, we have grid.arrange in library(gridExtra): library(gridExtra) p1 = qplot(price, data=diamonds) p2 = qplot(cut, data = diamonds) grid.arrange(p1, p2, nrow=2) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. If you want to learn more options, you can go here. 3.3.3 Some cool plots in library(GGally) There are some good extra plots based on ggplot2 in library(GGally). One of them is the equivalent of plot(dataset): library(GGally) ggpairs(diamonds[,5:10]) You can plot confidence intervals for regression coefficients easily: data(mtcars) mod = lm(mpg~wt+qsec+cyl,data=mtcars) ggcoef(mod) 3.4 More ggplot Today we’ll cover more ggplot. Last time we used qplot and today we’ll use the more general ggplot machinery. Plotting with ggplot can be more or less broken down into the following steps. Read in the data Add aesthetics (aes): Which variables go into the plot? What are the x and y? What variables are you using for color-coding? Add geoms: What kind of plot do you want? Do data transformations, if needed. Change labels/theme. We’ll see some concrete examples today. Let’s read in the diamonds data first. library(ggplot2) data(diamonds) Let’s create a stacked % barplot: ggplot(diamonds) + aes(x=cut, fill=color) + geom_bar() We can change the type of barplot easily by adding options in the geom_bar function: ggplot(diamonds) + aes(x=cut, fill=color) + geom_bar(position=&#39;fill&#39;) If you want side-by-side bars, you can use position = 'dodge' ggplot(diamonds) + aes(x=cut, fill=color) + geom_bar(position=&#39;dodge&#39;) We can use the same structure to produce a color-coded scatterplot: p = ggplot(diamonds) + aes(x=carat, y=price, color=cut) + geom_point() p Note that we used the option color in aes. We can break down plots in panels using facet_grid: p = p + facet_grid(. ~ cut) p And you can combine geoms. For example ggplot(diamonds) + aes(x=price) + geom_histogram(binwidth = 500, aes(y=..density..))+geom_density(color=&#39;red&#39;, size=1) 3.5 Axes, titles and labels The relevant commands here are ggtitle: for changing the title xlab, ylab: \\(x\\) and \\(y\\) labels xlim, ylim: limits / scale of the plot p + xlab(&quot;carat (weight)&quot;) + ylab(&quot;price ($)&quot;) + ggtitle(&quot;Price vs carat vs quality&quot;) + xlim(c(0,10))+ylim(c(0,30000)) You can also transform the axes p + coord_trans(x=&#39;log&#39;,y=&#39;log&#39;) References "],
["basic-programming.html", "Chapter 4 Basic programming", " Chapter 4 Basic programming "],
["basic-probability.html", "Chapter 5 Basic probability", " Chapter 5 Basic probability "],
["confidence-intervals-and-hypothesis-tests.html", "Chapter 6 Confidence intervals and hypothesis tests 6.1 One normal mean 6.2 Two independent normal means 6.3 \\(\\chi^2\\)-tests of independence for categorical variables 6.4 Pairwise comparisons of normal means: Tukey HSD References", " Chapter 6 Confidence intervals and hypothesis tests 6.1 One normal mean A group of scientists recorded some measurements that are stored in the vector x: x = c(1,4,2,3,6,9,1,3,9,3) We can find the mean and standard deviation of x as follows: mean(x) ## [1] 4.1 sd(x) ## [1] 2.960856 The function summary provides quantiles, minimum, maximum, etc. summary(x) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 2.25 3.00 4.10 5.50 9.00 We can visualize x with a histogram or a boxplot, for example. The plots below are created using the functions hist and boxplot, which are in library(graphics): hist(x, col = &#39;orange&#39;) boxplot(x, col = &#39;pink&#39;, main = &quot;Boxplot of x&quot;) We can do \\(t\\)-tests and find normal confidence intervals for the population mean \\(\\mu\\) with the function t.test. For example, if we want to find a 99% confidence interval for the mean: t.test(x, conf.level = 0.99) ## ## One Sample t-test ## ## data: x ## t = 4.3789, df = 9, p-value = 0.001774 ## alternative hypothesis: true mean is not equal to 0 ## 99 percent confidence interval: ## 1.057163 7.142837 ## sample estimates: ## mean of x ## 4.1 We can change conf.level to any confidence level that we want. If we don’t specify anything, the default is 95% confidence. As you can see, t.test gives us a \\(p\\)-value. The output is self-explanatory: the \\(p\\)-value corresponds to the test \\(H_0: \\mu = 0\\) against \\(H_1: \\mu \\neq 0\\). If we want to change the hypothesized value under the null to some value that is not 0, we can change the argument mu of t.test. If we want to change the alternative to “less than” or “greater than”, instead of “not equal to”, we can set alternative to less or greater, respectively. For instance, if we want to test \\(H_0: \\mu = 5\\) against \\(H_1 : \\mu &lt; 5\\), the following R code will do it for us: t.test(x, mu = 5, alternative = &#39;less&#39;) ## ## One Sample t-test ## ## data: x ## t = -0.96123, df = 9, p-value = 0.1808 ## alternative hypothesis: true mean is less than 5 ## 95 percent confidence interval: ## -Inf 5.816352 ## sample estimates: ## mean of x ## 4.1 As always, you can get more information about the function if you type in ?t.test. 6.2 Two independent normal means A pharmaceutical is interested in knowing whether their new treatment is significantly different than the current gold standard. They collected a sample of 40 individuals: 20 of them were assigned the new treatment, and 20 of them were assigned the current treatment. The outcome is on an ordinal scale that goes from 0 to 100, where 0 is “bad” and 100 is “great”. The data can be found in the file pharma.csv, which is on the course website. The data has 2 columns: group and outcome: summary(pharma) ## group outcome ## current:20 Min. : 80.00 ## new :20 1st Qu.: 89.00 ## Median : 92.50 ## Mean : 92.30 ## 3rd Qu.: 98.25 ## Max. :100.00 If we want to get summaries by group (means, standard deviations, etc.), there are different ways to do it. Here’s one: summary(pharma[pharma$group==&#39;current&#39;,]) ## group outcome ## current:20 Min. : 83.00 ## new : 0 1st Qu.: 92.75 ## Median : 97.50 ## Mean : 95.55 ## 3rd Qu.:100.00 ## Max. :100.00 summary(pharma[pharma$group==&#39;new&#39;,]) ## group outcome ## current: 0 Min. : 80.00 ## new :20 1st Qu.: 85.25 ## Median : 89.50 ## Mean : 89.05 ## 3rd Qu.: 92.25 ## Max. :100.00 We’ll see other ways of creating summaries by different levels of a factor later in the semester. If we want to plot the outcomes by group, we can create a boxplot: boxplot(outcome ~ group, data = pharma, main = &quot;Boxplots of outcome by group&quot;, col = c(&#39;red&#39;, &#39;blue&#39;)) We could’ve also used the command boxplot(pharma$outcome ~ pharma$group), but I think the command above is cleaner. If we want to create histograms of outcomes by groups, here’s an option: par(mfrow=c(2,1)) hist(pharma$outcome[pharma$group==&#39;current&#39;], main = &quot;Outcomes for current treatment&quot;, xlab=&#39;outcome&#39;, col = &#39;red&#39;) hist(pharma$outcome[pharma$group==&#39;new&#39;], main = &quot;Outcomes for new treatment&quot;, xlab = &#39;outcome&#39;, col = &#39;blue&#39;) Some comments on the code: par(mfrow=c(2,1)) tells R that we want a plot that has 2 rows and 1 column xlab changes the label on the x-axis of the plot The pharmaceutical is interested in knowing whether the population means of the health outcomes are different at the 0.01 significance level. That is, if \\(\\mu_C\\) and \\(\\mu_N\\) are the population means of outcome for the current and new treatments, respectively, the pharmaceutical wants to test \\(H_0: \\mu_C = \\mu_N\\) against \\(H_1 : \\mu_C \\neq \\mu_N\\) at the 0.01 significance level. We can do a two-sample \\(t\\)-test with t.test: t.test(outcome ~ group, conf.level = 0.99, data = pharma) ## ## Welch Two Sample t-test ## ## data: outcome by group ## t = 3.8381, df = 37.451, p-value = 0.0004622 ## alternative hypothesis: true difference in means is not equal to 0 ## 99 percent confidence interval: ## 1.904267 11.095733 ## sample estimates: ## mean in group current mean in group new ## 95.55 89.05 We can change the hypothesized difference in means under the null with the argument mu and we can change the alternative to “less than” or “greater than” with the argument alternative, just as we did with the one-sample \\(t\\)-test we covered in the previous section. As you can see, the treatments are significantly different at the 0.01 significance level (the \\(p\\)-value is less than 0.01 and the 99% confidence interval doesn’t cover 0). However, we wouldn’t recommend marketing this new drug: the new treatment is significantly worse than the current treatment. 6.3 \\(\\chi^2\\)-tests of independence for categorical variables The hsb2 dataset in library(openintro) has standardized test scores and background information for a sample of 200 highschoolers. Let’s read in the data: library(openintro) ## Please visit openintro.org for free statistics materials ## ## Attaching package: &#39;openintro&#39; ## The following objects are masked _by_ &#39;.GlobalEnv&#39;: ## ## diamonds, hsb2 ## The following object is masked from &#39;package:ggplot2&#39;: ## ## diamonds ## The following objects are masked from &#39;package:datasets&#39;: ## ## cars, trees data(hsb2) If you want more information about the dataset, you can find it by typing ?hsb2. If we want to get a quick look at the variables in the dataset, we can use str: str(hsb2) ## &#39;data.frame&#39;: 200 obs. of 11 variables: ## $ id : int 70 121 86 141 172 113 50 11 84 48 ... ## $ gender : chr &quot;male&quot; &quot;female&quot; &quot;male&quot; &quot;male&quot; ... ## $ race : chr &quot;white&quot; &quot;white&quot; &quot;white&quot; &quot;white&quot; ... ## $ ses : Factor w/ 3 levels &quot;low&quot;,&quot;middle&quot;,..: 1 2 3 3 2 2 2 2 2 2 ... ## $ schtyp : Factor w/ 2 levels &quot;public&quot;,&quot;private&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ prog : Factor w/ 3 levels &quot;general&quot;,&quot;academic&quot;,..: 1 3 1 3 2 2 1 2 1 2 ... ## $ read : int 57 68 44 63 47 44 50 34 63 57 ... ## $ write : int 52 59 33 44 52 52 59 46 57 55 ... ## $ math : int 41 53 54 47 57 51 42 45 54 52 ... ## $ science: int 47 63 58 53 53 63 53 39 58 50 ... ## $ socst : int 57 61 31 56 61 61 61 36 51 51 ... Suppose that a team of social scientists want to test whether the distribution of ses depends on race. First, we can create a table: table(hsb2$ses, hsb2$race) ## ## african american asian hispanic white ## low 11 3 9 24 ## middle 6 5 11 73 ## high 3 3 4 48 It’s hard to see whether race depends on ses by looking at the raw counts. We can create columns with row and column percentages with prop.table. First, we save the original table with raw counts in a variable. tab = table(hsb2$ses, hsb2$race) If we want row percentages (i.e. the sum of each row of the table is equal to 1): prop.table(tab, margin = 1) ## ## african american asian hispanic white ## low 0.23404255 0.06382979 0.19148936 0.51063830 ## middle 0.06315789 0.05263158 0.11578947 0.76842105 ## high 0.05172414 0.05172414 0.06896552 0.82758621 If we want column percentages (i.e. the sum of each column of the table is equal to 1): prop.table(tab, margin = 2) ## ## african american asian hispanic white ## low 0.5500000 0.2727273 0.3750000 0.1655172 ## middle 0.3000000 0.4545455 0.4583333 0.5034483 ## high 0.1500000 0.2727273 0.1666667 0.3310345 Finally, if we want overall percentages instead (i.e. the sum of all the entries in the table is equal to 1): prop.table(tab) ## ## african american asian hispanic white ## low 0.055 0.015 0.045 0.120 ## middle 0.030 0.025 0.055 0.365 ## high 0.015 0.015 0.020 0.240 These prop.tables aren’t very easy to look at, either: they have too many decimal places. We can round them as with round: round(prop.table(tab, margin = 1), 3) ## ## african american asian hispanic white ## low 0.234 0.064 0.191 0.511 ## middle 0.063 0.053 0.116 0.768 ## high 0.052 0.052 0.069 0.828 If we want 5 decimal places instead, we would change the 3 to a 5. We can create barplots with the tables and prop.tables: barplot(tab, legend.text = T) barplot(prop.table(tab, margin = 2), legend.text = T) The position of the legends isn’t great… We’ll see how to fix that later in the semester. Finally, the code below runs a \\(\\chi^2\\)-test: chisq.test(tab) ## Warning in chisq.test(tab): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: tab ## X-squared = 18.516, df = 6, p-value = 0.005064 The \\(p\\)-value is significant at the 0.05 significance level. 6.4 Pairwise comparisons of normal means: Tukey HSD Let’s work again with hsb2 in library(openintro). Suppose that we want to compare the average scores in math among the levels of race doing pairwise tests, using Tukey HSD. The code is simple: mod = aov(math~race, data=hsb2) TukeyHSD(mod) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = math ~ race, data = hsb2) ## ## $race ## diff lwr upr p adj ## asian-african american 10.5227273 1.838424 19.207030 0.0104479 ## hispanic-african american 0.6666667 -6.337737 7.671071 0.9947149 ## white-african american 7.2224138 1.704074 12.740754 0.0046342 ## hispanic-asian -9.8560606 -18.279657 -1.432465 0.0145446 ## white-asian -3.3003135 -10.535462 3.934835 0.6389480 ## white-hispanic 6.5557471 1.457520 11.653975 0.0056430 We can check whether the pairwise differences are significant by checking the \\(p\\)-values. You can change the confidence level of the corrected intervals with the argument conf.level. For example, if we want 99% confidence intervals instead: TukeyHSD(mod, conf.level = 0.99) ## Tukey multiple comparisons of means ## 99% family-wise confidence level ## ## Fit: aov(formula = math ~ race, data = hsb2) ## ## $race ## diff lwr upr p adj ## asian-african american 10.5227273 -0.04702112 21.0924757 0.0104479 ## hispanic-african american 0.6666667 -7.85846043 9.1917938 0.9947149 ## white-african american 7.2224138 0.50598962 13.9388380 0.0046342 ## hispanic-asian -9.8560606 -20.10849978 0.3963786 0.0145446 ## white-asian -3.3003135 -12.10628138 5.5056544 0.6389480 ## white-hispanic 6.5557471 0.35064587 12.7608484 0.0056430 References "],
["multiple-linear-regression.html", "Chapter 7 Multiple linear regression 7.1 Exploratory data analysis 7.2 Fitting regression models with the lm function 7.3 Automatic model selection 7.4 Prediction 7.5 Interactions References", " Chapter 7 Multiple linear regression We’ll analyze a dataset in Sheather (2009) that has information about 150 Italian restaurants in Manhattan that were open in 2001 (some of them are closed now). The variables are: Case: case-indexing variable Restaurant: name of the restaurant Price: average price of a meal and a drink Food: average Zagat rating of the quality of the food (from 0 to 25) Decor: same as above, but with quality of the decor Service: same as above, but with quality of service East: it is equal to 1 if the restaurant is on the East Side (i.e. east of Fifth Ave) In our analysis, the response variable will be Price. 7.1 Exploratory data analysis The function pairs creates a scatterplot matrix: pairs(nyc[,-c(1,2)]) I wrote nyc[,-c(1,2)] instead of nyc so that the first two variables, Case and Restaurant, are not plotted. We can get quick and dirty summaries of the variables with summary: summary(nyc[,-c(1,2)]) ## Price Food Decor Service East ## Min. :19.00 Min. :16.00 Min. : 6.00 Min. :14.00 East:95 ## 1st Qu.:35.25 1st Qu.:19.00 1st Qu.:16.00 1st Qu.:18.00 West:55 ## Median :42.00 Median :21.00 Median :18.00 Median :20.00 ## Mean :42.62 Mean :20.61 Mean :17.69 Mean :19.39 ## 3rd Qu.:49.75 3rd Qu.:22.00 3rd Qu.:19.00 3rd Qu.:21.00 ## Max. :65.00 Max. :25.00 Max. :25.00 Max. :24.00 The function ggpairs in library(GGally) produces the equivalent plot, but with ggplot2: library(GGally) ggpairs(nyc[,-c(1,2)]) Do you see any interesting patterns? 7.2 Fitting regression models with the lm function Fitting regression models with R is easy. For example, we can fit a model where the outcome is Price and the predictors are Food, Decor, Service, and East with the code mod = lm(Price ~ Food + Decor + Service + East, data = nyc) Calling the object mod only gives us coefficients: mod ## ## Call: ## lm(formula = Price ~ Food + Decor + Service + East, data = nyc) ## ## Coefficients: ## (Intercept) Food Decor Service EastWest ## -23.644163 1.634869 1.865549 0.007626 -1.613350 If we want \\(p\\)-values, \\(R^2\\), and more, we can get them with summary(): summary(mod) ## ## Call: ## lm(formula = Price ~ Food + Decor + Service + East, data = nyc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.7995 -3.8323 0.0997 3.3449 16.8484 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -23.644163 5.079278 -4.655 7.25e-06 *** ## Food 1.634869 0.384961 4.247 3.86e-05 *** ## Decor 1.865549 0.221396 8.426 3.22e-14 *** ## Service 0.007626 0.432210 0.018 0.986 ## EastWest -1.613350 1.000385 -1.613 0.109 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.692 on 145 degrees of freedom ## Multiple R-squared: 0.6466, Adjusted R-squared: 0.6369 ## F-statistic: 66.34 on 4 and 145 DF, p-value: &lt; 2.2e-16 We can get diagnostic plots by plotting the model. That will give us 4 diagnostic plots. We can arrange them in a figure with 2 rows and 2 columns with par(mfrow=c(2,2)): par(mfrow=c(2,2)) plot(mod) If, for some reason, we want them in 1 row and 4 columns: par(mfrow=c(1,4)) plot(mod) The instruction par(mfrow=c(&lt;rows&gt;, &lt;columns&gt;) isn’t specific to “models”. We can use it to arrange figures with multiple rows and columns of plots in library(graphics). Unfortunately, it doesn’t work with ggplot2. The analogue instruction for ggplot2 is grid.arrange (see ggplot2 handout for examples). We can extract diagnostics from mod. For example, if we want to extract Cook’s distances and plot them against observation number, we can use: cookd = cooks.distance(mod) plot(cookd) Other useful functions are hatvalues (for leverages), residuals (for residuals), and rstandard (for standardized residuals). 7.3 Automatic model selection 7.3.1 Backward, forward, and stepwise Backward selection with AIC: step(mod, direction=&#39;backward&#39;) ## Start: AIC=526.64 ## Price ~ Food + Decor + Service + East ## ## Df Sum of Sq RSS AIC ## - Service 1 0.01 4698.0 524.64 ## &lt;none&gt; 4698.0 526.64 ## - East 1 84.27 4782.2 527.30 ## - Food 1 584.35 5282.3 542.22 ## - Decor 1 2300.45 6998.4 584.42 ## ## Step: AIC=524.64 ## Price ~ Food + Decor + East ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 4698.0 524.64 ## - East 1 87.24 4785.2 525.40 ## - Food 1 1166.83 5864.8 555.91 ## - Decor 1 3062.26 7760.2 597.92 ## ## Call: ## lm(formula = Price ~ Food + Decor + East, data = nyc) ## ## Coefficients: ## (Intercept) Food Decor EastWest ## -23.628 1.640 1.867 -1.616 If we want to do forward selection, we have to give a starting model and a bigger model that contains the all the variables that we might want to include in our model. nullmod = lm(Price ~ 1, data = nyc) # no variables fwd = step(nullmod, scope=list(upper=mod), direction=&#39;forward&#39;) ## Start: AIC=674.68 ## Price ~ 1 ## ## Df Sum of Sq RSS AIC ## + Decor 1 7157.2 6138.1 560.75 ## + Service 1 5794.1 7501.3 590.83 ## + Food 1 5505.8 7789.5 596.48 ## + East 1 380.3 12915.0 672.33 ## &lt;none&gt; 13295.3 674.68 ## ## Step: AIC=560.75 ## Price ~ Decor ## ## Df Sum of Sq RSS AIC ## + Food 1 1352.93 4785.2 525.40 ## + Service 1 763.57 5374.6 542.82 ## + East 1 273.34 5864.8 555.91 ## &lt;none&gt; 6138.1 560.75 ## ## Step: AIC=525.4 ## Price ~ Decor + Food ## ## Df Sum of Sq RSS AIC ## + East 1 87.239 4698.0 524.64 ## &lt;none&gt; 4785.2 525.40 ## + Service 1 2.980 4782.2 527.30 ## ## Step: AIC=524.64 ## Price ~ Decor + Food + East ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 4698 524.64 ## + Service 1 0.010086 4698 526.64 In the code above, the starting point was a model with no variables (nullmod) and the model that included the variables under consideration is mod (which contains Food, Service, Decor, and East). We can do forward selection starting with a model that has some variable(s) already. For example, we can start with a model that has Service already in. mod2 = lm( Price ~ Service, data = nyc) fwd = step(mod2, scope=list(upper=mod), direction=&#39;forward&#39;) ## Start: AIC=590.83 ## Price ~ Service ## ## Df Sum of Sq RSS AIC ## + Decor 1 2126.70 5374.6 542.82 ## + Food 1 498.33 7002.9 582.52 ## &lt;none&gt; 7501.3 590.83 ## + East 1 7.05 7494.2 592.69 ## ## Step: AIC=542.82 ## Price ~ Service + Decor ## ## Df Sum of Sq RSS AIC ## + Food 1 592.34 4782.2 527.30 ## + East 1 92.26 5282.3 542.22 ## &lt;none&gt; 5374.6 542.82 ## ## Step: AIC=527.3 ## Price ~ Service + Decor + Food ## ## Df Sum of Sq RSS AIC ## + East 1 84.268 4698.0 526.64 ## &lt;none&gt; 4782.2 527.30 ## ## Step: AIC=526.64 ## Price ~ Service + Decor + Food + East We can do stepwise regression with direction = 'both'. In stepwise regression, variables can get in or out of the model. We can specify the smallest and biggest model in our search with scope. For example, if we want to start our stepwise search with a model has Service as a predictor and we want to restrict our search to models that include Service and potentially include all the other predictors: mod2 = lm( Price ~ Service, data = nyc) fwd = step(mod2, scope=list(lower=mod2, upper=mod), direction=&#39;both&#39;) ## Start: AIC=590.83 ## Price ~ Service ## ## Df Sum of Sq RSS AIC ## + Decor 1 2126.70 5374.6 542.82 ## + Food 1 498.33 7002.9 582.52 ## &lt;none&gt; 7501.3 590.83 ## + East 1 7.05 7494.2 592.69 ## ## Step: AIC=542.82 ## Price ~ Service + Decor ## ## Df Sum of Sq RSS AIC ## + Food 1 592.34 4782.2 527.30 ## + East 1 92.26 5282.3 542.22 ## &lt;none&gt; 5374.6 542.82 ## - Decor 1 2126.70 7501.3 590.83 ## ## Step: AIC=527.3 ## Price ~ Service + Decor + Food ## ## Df Sum of Sq RSS AIC ## + East 1 84.27 4698.0 526.64 ## &lt;none&gt; 4782.2 527.30 ## - Food 1 592.34 5374.6 542.82 ## - Decor 1 2220.71 7002.9 582.52 ## ## Step: AIC=526.64 ## Price ~ Service + Decor + Food + East ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 4698.0 526.64 ## - East 1 84.27 4782.2 527.30 ## - Food 1 584.35 5282.3 542.22 ## - Decor 1 2300.45 6998.4 584.42 We can change our selection criterion to BIC by adding the command k = log(number of observations). For example, n = nrow(nyc) step(mod, direction=&#39;backward&#39;, k = log(n)) ## Start: AIC=541.69 ## Price ~ Food + Decor + Service + East ## ## Df Sum of Sq RSS AIC ## - Service 1 0.01 4698.0 536.68 ## - East 1 84.27 4782.2 539.35 ## &lt;none&gt; 4698.0 541.69 ## - Food 1 584.35 5282.3 554.27 ## - Decor 1 2300.45 6998.4 596.46 ## ## Step: AIC=536.68 ## Price ~ Food + Decor + East ## ## Df Sum of Sq RSS AIC ## - East 1 87.24 4785.2 534.43 ## &lt;none&gt; 4698.0 536.68 ## - Food 1 1166.83 5864.8 564.95 ## - Decor 1 3062.26 7760.2 606.95 ## ## Step: AIC=534.43 ## Price ~ Food + Decor ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 4785.2 534.43 ## - Food 1 1352.9 6138.1 566.77 ## - Decor 1 3004.3 7789.5 602.51 ## ## Call: ## lm(formula = Price ~ Food + Decor, data = nyc) ## ## Coefficients: ## (Intercept) Food Decor ## -25.678 1.730 1.845 7.3.2 All subsets selection with library(leaps) If we want to find the “best” model given a set of predictors according to BIC or adjusted \\(R^2\\), library(leaps) is helpful. For example, if we want to consider all models that might contain Food, Decor, Service, and East: library(leaps) allsubs = regsubsets(Price ~ Food + Decor + Service + East, data = nyc) We can see the best models with 1, 2, 3, and 4 predictors using the summary function: summary(allsubs) ## Subset selection object ## Call: regsubsets.formula(Price ~ Food + Decor + Service + East, data = nyc) ## 4 Variables (and intercept) ## Forced in Forced out ## Food FALSE FALSE ## Decor FALSE FALSE ## Service FALSE FALSE ## EastWest FALSE FALSE ## 1 subsets of each size up to 4 ## Selection Algorithm: exhaustive ## Food Decor Service EastWest ## 1 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 3 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; ## 4 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; If we restrict ourselves to all models that have, say, exactly 2 predictors, the “best” models according to AIC, BIC, and adjusted \\(R^2\\) will coincide: it will be the model with 2 predictors that has the smallest residual sum of squares. The overall “best” model will be one of the 4 “best” models for a fixed number of predictors. AIC and BIC need not agree on the overall best model, because they penalize model sizes differently (the penalty for AIC is smaller, which favors bigger models). We can visualize the BICs of the “best” models (the model at the top of the plot is the best model overall): plot(allsubs) We can also visualize the adjusted \\(R^2\\)s: plot(allsubs, scale = &#39;adjr&#39;) I haven’t found a way to get AICs, unfortunately. 7.4 Prediction The dataset nyctest has data for some Italian restaurants that weren’t included in nyc. Let’s see how well we predict the prices of the meals. We’ll use the following model mod = lm(Price ~ Food + Decor + East, data = nyc) We can find point predictions and 99% prediction intervals as follows: preds = predict(mod, newdata = nyctest, interval = &#39;prediction&#39;, level = 0.99) preds ## fit lwr upr ## 1 44.44261 29.45164 59.43358 ## 2 46.05904 31.15867 60.95941 ## 3 39.04475 24.14123 53.94827 ## 4 39.27259 24.34107 54.20410 ## 5 54.94082 39.92882 69.95282 ## 6 35.76544 20.77548 50.75540 ## 7 37.40510 22.47519 52.33500 ## 8 44.41939 29.53641 59.30237 ## 9 49.56619 34.62748 64.50489 ## 10 46.05904 31.15867 60.95941 ## 11 41.14008 26.19025 56.08991 ## 12 41.14008 26.19025 56.08991 ## 13 39.29582 24.35479 54.23684 ## 14 41.39114 26.39525 56.38704 ## 15 33.69334 18.65313 48.73356 ## 16 36.01651 21.01412 51.01890 ## 17 44.67045 29.71621 59.62469 ## 18 46.31011 31.32610 61.29411 Let’s compare them to the actual prices: compare = cbind(preds, nyctest$Price) We can find a column that tests whether the prediction interval contain the prices: test = (compare[,4]&gt;=compare[,2]) &amp; (compare[,4] &lt;= compare[,3]) cbind(compare, test) ## fit lwr upr test ## 1 44.44261 29.45164 59.43358 43 1 ## 2 46.05904 31.15867 60.95941 45 1 ## 3 39.04475 24.14123 53.94827 43 1 ## 4 39.27259 24.34107 54.20410 43 1 ## 5 54.94082 39.92882 69.95282 58 1 ## 6 35.76544 20.77548 50.75540 54 0 ## 7 37.40510 22.47519 52.33500 31 1 ## 8 44.41939 29.53641 59.30237 50 1 ## 9 49.56619 34.62748 64.50489 46 1 ## 10 46.05904 31.15867 60.95941 50 1 ## 11 41.14008 26.19025 56.08991 39 1 ## 12 41.14008 26.19025 56.08991 43 1 ## 13 39.29582 24.35479 54.23684 45 1 ## 14 41.39114 26.39525 56.38704 40 1 ## 15 33.69334 18.65313 48.73356 23 1 ## 16 36.01651 21.01412 51.01890 38 1 ## 17 44.67045 29.71621 59.62469 39 1 ## 18 46.31011 31.32610 61.29411 50 1 We can find the proportion of intervals that trap the true price as mean(test) ## [1] 0.9444444 7.5 Interactions Fitting interactions with R amounts to writing a product term in the lm statement. For example, if we’re working with the hsb2 dataset in library(openintro) and we want to fit a model to predict math scores as a function of the score in writing, socioeconomic status, and an interaction between the two, you can use the code below: library(openintro) data(hsb2) mod = lm(math ~ write + ses + ses*write , data = hsb2) summary(mod) ## ## Call: ## lm(formula = math ~ write + ses + ses * write, data = hsb2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.0179 -4.5783 -0.2104 4.4228 21.5940 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 20.336920 5.861562 3.470 0.000642 *** ## write 0.569636 0.113860 5.003 1.26e-06 *** ## sesmiddle 1.938395 7.314626 0.265 0.791289 ## seshigh 2.525714 8.265754 0.306 0.760264 ## write:sesmiddle 0.006858 0.140908 0.049 0.961234 ## write:seshigh 0.026098 0.153401 0.170 0.865085 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.329 on 194 degrees of freedom ## Multiple R-squared: 0.4034, Adjusted R-squared: 0.388 ## F-statistic: 26.24 on 5 and 194 DF, p-value: &lt; 2.2e-16 References Sheather, Simon. A modern approach to regression with R. Springer Science &amp; Business Media, 2009. Multiple and logistic regression, Datacamp course by Ben Baumer. "]
]
